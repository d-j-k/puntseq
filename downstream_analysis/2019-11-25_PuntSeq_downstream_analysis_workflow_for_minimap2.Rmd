---
title: "Metagenomics analysis workflow on MinION data"
author: "by PuntSeq: [Andre Holzer](https://orcid.org/0000-0003-2439-6364), [Lara Urban](https://orcid.org/0000-0002-5445-9314) and [Maximilian Stammnitz](https://orcid.org/0000-0002-1704-9199)"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
    theme: paper
    number_sections: false
    fig_width: 7
    fig_height: 6
    fig_caption: true
  pdf_document:
    toc: true
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part 0: Initiation

This markdown allows to reproduce the downstream processing performed on minimap2 classifier outputs. It combines R, Python and Bash code and requires the following packages/dependencies to be installed on your computer before execution:

1.) You will need to have a version of conda installed. Please read here (https://conda.io/projects/conda/en/latest/user-guide/install/index.html?highlight=conda) how to install conda.

2.) Download the conda environment.yml file ("PuntSeq-analysis-env.yml") from our GitHub repository (https://github.com/d-j-k/puntseq) and create a local environment with the environment.yml file by executing the follwoing command from your shell:

```{bash eval=FALSE}
wget --no-check-certificate https://raw.githubusercontent.com/d-j-k/puntseq/master/conda_environment/PuntSeq-analysis-env.yaml
conda env create -f PuntSeq-analysis-env.yaml
```

## Installation & loading of required R packages
All packages which are required to execulte the anaylsis will be loaded and if not already done so first installed on your machine. The following lines of code will do both automatically for you. (In case there should be any erros while trying to insall any package, please perform installation of the required packages manually)
```{r eval=FALSE}
list.of.packages = c("tidyverse","knitr","hash","RColorBrewer","scales","ggplot2", "ggpubr", "ggsci","FactoMineR", "factoextra","ggpmisc","stringr","reticulate","dendextend","pheatmap","grid") 
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages) > 0) {install.packages(new.packages)}
lapply(list.of.packages, require, character.only=T)
```
## Global variables and functions
Next, global variables and functions are defined (Can be modify if nessesary)
```{r eval=FALSE}
# Date
date <- format(Sys.Date(), format="%Y-%m-%d")

# Set working directory 
setwd("./")

# Name of the output directory (will be created in your current working directory)
outfolder <- str_c(date,"_PuntSeq_Downstream-metagenomics-analysis/")

# Basecaller
bcaller <- "Guppy"  

# Classifier
classifyr <- "minimap" 

# Define which downsampling dataset will be used
dsampling <- 0  # 0: use orginal downsampling (by PuntSeq 2019-11-13), 1: generate new downsampling

# Color sheme for locations 1-9.1/9.2 + positiv & negativ control
lcolors <- c("1" = "#2157A4", "2" = "#3694D1", "3" = "#65C6E8", "4" = "#9DD7ED", "5" = "#F7EC73", "6" = "#FDCB44", "7" = "#F1861E", "8" = "#E63A11", "9.1" = "#D61015", "9.2" = "#D61015", "Mock" = "#636363","P" = "#636363", "N" = "#f0f0f0")

# Color sheme for sampling timepoints in April, June and August 
tcolors <- c("April" = "#f0f0f0", "June" = "#bdbdbd", "August" = "#636363") # gerys
          #c("April" = "#66c2a5", "June" = "#fc8d62", "August" = "#8da0cb") # qualitative
          #c("April" = "#e0ecf4", "June" = "#9ebcda", "August" = "#8856a7") # sequential

# Scientfic scale function
scientific_1 <- function(x) {
  parse(text=gsub("e", " %*% 10^", scales::scientific_format()(x)))
}
```
and main directoriy for output data is created.
```{r eval=FALSE}
system(str_c("mkdir ",outfolder))
```

## Downloading classifier output data
Classifier outputs comprising raw count data for all samples taken in April, June and August can directly be downloaded from our GitHub directory (https://github.com/d-j-k/puntseq). By executing the following lines of code this will automatically be performed saving the files to the "<OUTFOLDER>/Classifier_output" directory.
```{r eval=FALSE}
# Create sub-output directory
system(str_c("mkdir ",outfolder,"Classifier_output/"))

# download classifier output data on family level for april samples
infile_april_family <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/minimap2_k12_family_april.txt")
destfile_april_family=str_c(outfolder,"Classifier_output/",bcaller,"_April_",classifyr,"_family.tsv")
if(!file.exists(destfile_april_family)){
  res <- tryCatch(download.file(infile_april_family, destfile_april_family, method="auto"), error=function(e) 1)
}

# download classifier output data on genus level for april samples
infile_april_genus <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/minimap2_k12_genus_april.txt")
destfile_april_genus=str_c(outfolder,"Classifier_output/",bcaller,"_April_",classifyr,"_genus.tsv")
if(!file.exists(destfile_april_genus)){
  res <- tryCatch(download.file(infile_april_genus, destfile_april_genus, method="auto"), error=function(e) 1)
}

# download classifier output data on family level for june samples
infile_june_family <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/minimap2_k12_family_june.txt")
destfile_june_family=str_c(outfolder,"Classifier_output/",bcaller,"_June_",classifyr,"_family.tsv")
if(!file.exists(destfile_june_family)){
  res <- tryCatch(download.file(infile_june_family, destfile_june_family, method="auto"), error=function(e) 1)
}

# download classifier output data on genus level for june samples
infile_june_genus <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/minimap2_k12_genus_june.txt")
destfile_june_genus=str_c(outfolder,"Classifier_output/",bcaller,"_June_",classifyr,"_genus.tsv")
if(!file.exists(destfile_june_genus)){
  res <- tryCatch(download.file(infile_june_genus, destfile_june_genus, method="auto"), error=function(e) 1)
}

# download classifier output data on family level for august samples
infile_august_family <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/minimap2_k12_family_august.txt")
destfile_august_family=str_c(outfolder,"Classifier_output/",bcaller,"_August_",classifyr,"_family.tsv")
if(!file.exists(destfile_august_family)){
  res <- tryCatch(download.file(infile_august_family, destfile_august_family, method="auto"), error=function(e) 1)
}

# download classifier output data on genus level for august samples
infile_august_genus <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/minimap2_k12_genus_august.txt")
destfile_august_genus=str_c(outfolder,"Classifier_output/",bcaller,"_August_",classifyr,"_genus.tsv")
if(!file.exists(destfile_august_genus)){
  res <- tryCatch(download.file(infile_august_genus, destfile_august_genus, method="auto"), error=function(e) 1)
}

# download total read numbers for all timepoints and locations
infile_root <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/minimap2_k12_root_april-june-august.txt")
destfile_root=str_c(outfolder,"Classifier_output/",bcaller,"_",classifyr,"_root_april-june-august.tsv")
if(!file.exists(destfile_root)){
  res <- tryCatch(download.file(infile_root, destfile_root, method="auto"), error=function(e) 1)
}
```
## Downloading additional metadata
```{r}
# Create sub-output directory
system(str_c("mkdir ",outfolder,"Metadata/"))

# download metadata
infile_metadata <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/metadata/Metadata_guppy_minimap2_table2.txt")
destfile_metadata=str_c(outfolder,"Metadata/Metadata_guppy_minimap2_table2.txt")
if(!file.exists(destfile_metadata)){
  res <- tryCatch(download.file(infile_metadata, destfile_metadata, method="auto"), error=function(e) 1)
}
```

## Initialise Python engine & conda environment
```{r}
# e. use python engine and conda enviornment

#devtools::install_github("rstudio/reticulate") # install the developer version in case there are any errors with activating the conda environment
library(reticulate)
use_condaenv("PuntSeq-analysis-env", required = TRUE)
knitr::knit_engines$set(python = reticulate::eng_python)
py_config()
```

# Part 1: Downsampling & Quality Control
## Continuous rarefactions of 16S classifications
### Load data
```{r}
# a. Classifications with minimap2 vs. SILVA 16S (release 132)
classifications.genus <- classifications.family <- vector(mode = 'list', length = 3)
names(classifications.genus) <- names(classifications.family) <- c("April", "June", "August")
classifications.family$April <- read.table(destfile_april_family, sep = '\t', check.names = F, header = T, fill = T)
classifications.family$June <- read.table(destfile_june_family, sep = '\t', check.names = F, header = T, fill = T)
classifications.family$August <- read.table(destfile_august_family, sep = '\t', check.names = F, header = T, fill = T)
classifications.genus$April <- read.table(destfile_april_genus, sep = '\t', check.names = F, header = T, fill = T)
classifications.genus$June <- read.table(destfile_june_genus, sep = '\t', check.names = F, header = T, fill = T)
classifications.genus$August <- read.table(destfile_august_genus, sep = '\t', check.names = F, header = T, fill = T)

# b. Standardise column naming and order, remove "uncultured" and "unknown" taxa
classifications.family <- lapply(classifications.family, function(x){colnames(x)[1] <- 'Name'; ind <- match(c('Name', '1', '2', '3', '4', '5', '6', '7', '8', '9.1', '9.2', 'N', 'P'), colnames(x));
ind <- ind[!is.na(ind)]; x <- x[,ind]; colnames(x)[grep('P',colnames(x))] <- 'Mock'; x <- x[-grep('^Unknown Family$|^uncultured$',x[,'Name']),]; return(x)})

classifications.genus <- lapply(classifications.genus, function(x){colnames(x)[1] <- 'Name'; ind <- match(c('Name', '1', '2', '3', '4', '5', '6', '7', '8', '9.1', '9.2', 'N', 'P'), colnames(x));
ind <- ind[!is.na(ind)]; x <- x[,ind]; colnames(x)[grep('P',colnames(x))] <- 'Mock'; x <- x[-grep('^uncultured$',x[,'Name']),]; return(x)})

```

### Sampling functions
```{r}
# a. Sample
sample_classifications <- function(x, n_rep, read_steps){
  
  if(nrow(x) > 0){
    
    # subsample multinomially for each
    sampling.x <-  do.call(cbind, lapply(read_steps, function(y) rmultinom(n = n_rep, size = y, prob = x[,2])))
    sampling.x.sets <- cbind(as.character(x[,1]),sampling.x)
    sampling.x.sets <- sampling.x.sets[!apply(sampling.x, 1, function(x){all(x == 0)}),]
    
    # calculate sats
    x <- cbind(x, sampling.x)
    summary.x <- t(rbind(mapply(function(ind) {get_richness_shannon(x = x[,c(1,ind)])}, ind = 3:ncol(x)),
                         mapply(function(ind) {get_simpson(x = x[,c(1,ind)])}, ind = 3:ncol(x))))
    
    # output
    summary.x <- matrix(unlist(summary.x), nrow = nrow(summary.x), ncol = 4)
    return(list(stats = summary.x, sets = sampling.x.sets))
    
  }else{
    
    # output
    return(matrix(NA, nrow = length(read_steps), ncol = 4))
    
  }
  
}

# b. Calculate sample richness, Shannon diversity index and evenness
get_richness_shannon <- function(x){
  
  # a. remove NAs/0s (if present)
  if(any(x[,2] == 0 | is.na(x[,2]))){
    x <- x[-which(x[,2] == 0 | is.na(x[,2])),]
  }
  
  # b. individuals in pool
  total_N <- sum(as.numeric(as.character(x[,2])))
  
  # c. type richness
  richness <- nrow(x)
  
  # d. calculate shannon index: iterate over each species/genus/order/phylum
  shannon_H <- -sum(apply(x, 1, function(y) {p_i <- as.numeric(y[2])/total_N; shannon_H <- p_i * log(p_i); return(shannon_H)}))
  
  # e. calculate maximum possible Shannon H
  shannon_H_max <- log(richness)
  
  # f. calculate Shannon E (evenness)
  shannon_E <- shannon_H/shannon_H_max
  
  # g. output
  out <- list("Richness" = richness,
              "Shannon H" = shannon_H,
              "Shannon E" = shannon_E)
  return(out)
}

# c. Calculate Simpson's D
get_simpson <- function(x){
  
  # a. remove NAs/0s (if present)
  if(any(x[,2] == 0 | is.na(x[,2]))){
    x <- x[-which(x[,2] == 0 | is.na(x[,2])),]
  }
  
  # b. individuals in pool
  total_N <- sum(as.numeric(as.character(x[,2])))
  
  # c. type richness
  richness <- nrow(x)
  
  # d. Simpson's D
  ## adding a pseudocount to account for species presence of 1 read (!)
  simpson_D <- 1 - sum(apply(x, 1, function(y) {p_i <- c(c(as.numeric(y[2])+1)*as.numeric(y[2]))/c(c(total_N+1)*c(total_N)); return(p_i)}))
  
  # e. output
  out <- list("Simpson D" = simpson_D)
  return(out)
}

# d. Generate Michaelis Menten fit do study downsampling effects
mmfit <- function(x, xlims, type){
  
  # take values, dose = counts, response = richness
  if (type == 'genus'){
    x.counts <- x[-c(nrow(x)-3,nrow(x)-2,nrow(x)-1,nrow(x)),1]
    x.richness <- x[-c(nrow(x)-3,nrow(x)-2,nrow(x)-1,nrow(x)),2]
  }else if (type == 'family'){
    x.counts <- x[-c(nrow(x)-4,nrow(x)-2,nrow(x)-1,nrow(x)),1]
    x.richness <- x[-c(nrow(x)-4,nrow(x)-2,nrow(x)-1,nrow(x)),6]  
  }
  
  if (length(x.counts) > 3 & length(unique(x.richness)) != 1){
    
    # MM model
    datas <- data.frame(x.counts, x.richness)
    datas <- datas[!is.na(datas[,2]),]
    
    MMcurve <- formula(x.richness ~ Vmax*x.counts/(Km+x.counts))
    bestfit <- nls(formula = MMcurve, 
                   data = datas, 
                   start = list(Vmax = max(datas[,2]),
                                Km = max(datas[,1])/2))
    SconcRange <- seq(f = 0, t = xlims[2], by = 10)
    theorLine <- predict(bestfit, list(x.counts = SconcRange))
    
    # Output
    out <- list(summary(bestfit)$parameters[,1], xy = cbind(SconcRange, theorLine))
    return(out)
  }
  
}
```
 
### Rarefaction curves for Genus and Family 
This section is only nessesary if a new subsampling should be performed.
```{r}
if (dsampling == 1){
  
  # a. Parameters
  
  ## Number of reads
  read_steps <- seq(f = 100, t = 1800000, by = 100)
  
  ## Bootstraps per sampling depth
  n_rep <- 1
  
  ## Minimum number of supporting reads per genus/family/order/class/phylum for richness/shannon/simpson indices
  min_reads <- 5
  
  # c. Iterative sampling
  
  ## Prepare summary matrix
  sampling <- vector(mode = 'list', length = 12)
  names(sampling) <- c('1', '2', '3', '4', '5', '6', '7', '8', '9.1', '9.2', 'N', 'Mock')
  for (i in 1:length(sampling)){
    sampling[[i]] <- vector(mode = 'list', length = 3)
    names(sampling[[i]]) <- c("April", "June", "August")
    sampling[[i]]$April <- data.frame(matrix(NA, ncol = 9, nrow = length(read_steps)*n_rep))
    colnames(sampling[[i]]$April) <- c('Counts used',
                                       'Genus richness', 'Genus Shannon-H', 'Genus Shannon-E', 'Genus Simpson-D', 
                                       'Family richness', 'Family Shannon-H', 'Family Shannon-E', 'Family Simpson-D')
    sampling[[i]]$August <- sampling[[i]]$June <- sampling[[i]]$April
  }
  
  ## Iterate over each Cam site
  for (barcode in 1:length(sampling)){
    
    # Iterate over each time point (April, June, August) per Cam site
    for (time in 1:length(sampling[[barcode]])){
      
      ## Where we at, ma'es ?
      print(paste0('Processing sample ', names(sampling)[barcode], ' - ', names(classifications.family)[time]))
      
      ## Skip if data is yet missing
      barcode.name.tmp <- names(sampling)[barcode]
      out.ind <- grep(paste0('^',barcode.name.tmp,'$'), colnames(classifications.family[[time]]))
      if(length(out.ind) == 0){
        next
      }
      
      sampling[[barcode]][[time]][, 'Counts used'] <- rep(sort(rep(read_steps, n_rep)))
      
      ## fetch data
      tmp.data.family <- classifications.family[[time]][,c(1,out.ind)]
      tmp.data.genus <- classifications.genus[[time]][,c(1,out.ind)]
      
      ## sample multinomially on genus and family level
      tmp.data.genus <- tmp.data.genus[which(tmp.data.genus[,2] >= min_reads), ,drop = F]
      tmp.data.family <- tmp.data.family[which(tmp.data.family[,2] >= min_reads), ,drop = F]
      
      ## only take samplings which would lie below the actual number of classified reads (avoid UPsampling)
      sampling_thresh <- max(sum(tmp.data.genus[,2], na.rm = T), sum(tmp.data.family[,2], na.rm = T))
      sampling[[barcode]][[time]] <- sampling[[barcode]][[time]][!sampling[[barcode]][[time]][,1] > sampling_thresh,,drop = F]
      
      if(dim(tmp.data.genus)[1] > 0 & sum(tmp.data.genus[,2]) > read_steps[1]){
        read_steps.tmp <- seq(f = 100, t = max(sampling[[barcode]][[time]][,1]), by = 100)
        
        ## also generate richness & shannon indeces for each sample
        sampling[[barcode]][[time]][,c(2:5)] <- sample_classifications(x = tmp.data.genus, n_rep = n_rep, read_steps = read_steps.tmp)$stats
        sampling[[barcode]][[time]][,c(6:9)] <- sample_classifications(x = tmp.data.family, n_rep = n_rep, read_steps = read_steps.tmp)$stats
      }
  
      ## set samplings which would lie higher above taxon-level wise number of classified reads
      if(nrow(sampling[[barcode]][[time]]) > 0){
        sampling[[barcode]][[time]][sampling[[barcode]][[time]][,1] > sum(tmp.data.genus[,2], na.rm = T),2:5] <- NA
        sampling[[barcode]][[time]][sampling[[barcode]][[time]][,1] > sum(tmp.data.family[,2], na.rm = T),6:9] <- NA
      }
      
      ## at the end of the summary matrix, add original classification stats for genus, order and phylum
      sampling[[barcode]][[time]] <- rbind(sampling[[barcode]][[time]],
                                           rep(NA, ncol(sampling[[barcode]][[time]])),
                                           rep(NA, ncol(sampling[[barcode]][[time]])))
      colnames(sampling[[barcode]][[time]]) <- c('Counts used',
                                                 'Genus richness', 'Genus Shannon-H', 'Genus Shannon-E', 'Genus Simpson-D',
                                                 'Family richness', 'Family Shannon-H', 'Family Shannon-E', 'Family Simpson-D')
      sampling[[barcode]][[time]][nrow(sampling[[barcode]][[time]])-1,1] <- sum(tmp.data.genus[,2], na.rm = T)
      sampling[[barcode]][[time]][nrow(sampling[[barcode]][[time]])-1,2:4] <- as.numeric(get_richness_shannon(tmp.data.genus[,c(1,2)]))
      sampling[[barcode]][[time]][nrow(sampling[[barcode]][[time]])-1,5] <- as.numeric(get_simpson(tmp.data.genus[,c(1,2)]))
      sampling[[barcode]][[time]][nrow(sampling[[barcode]][[time]]),1] <- sum(tmp.data.family[,2], na.rm = T)
      sampling[[barcode]][[time]][nrow(sampling[[barcode]][[time]]),6:8] <- as.numeric(get_richness_shannon(tmp.data.family[,c(1,2)]))
      sampling[[barcode]][[time]][nrow(sampling[[barcode]][[time]]),9] <- as.numeric(get_simpson(tmp.data.family[,c(1,2)]))
    }
  }
}
```

### Summarise information: total data vs. 37,000 reads
```{r}

# i. Create output directories
system(str_c("mkdir ",outfolder,"Downsampling/"))
system(str_c("mkdir ",outfolder,"Downsampling/genus"))
system(str_c("mkdir ",outfolder,"Downsampling/family"))

# ii. Download original downsampling dataset if required
if (dsampling == 0){
  # download original rarefaction sampling data
  infile_rarefaction <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/downsampled/2019-11-13_guppy_minimap2_sampling.Rdata")
  destfile_rarefaction=str_c(outfolder,"Downsampling/2019-11-13_guppy_minimap2_sampling.Rdata")
  if(!file.exists(infile_rarefaction)){
  res <- tryCatch(download.file(infile_rarefaction, destfile_rarefaction, method="auto"), error=function(e) 1)
  }
  load(destfile_rarefaction)

  # download all files
  for (level in c("family","genus")){
    for (location in c("1","2","3","4","5","6","7","8","9.1","9.2","Mock","N")){
      for (Time in c("April","June","August")){
        infile_tmp <- str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/downsampled/2019-11-13_guppy_minimap2_sampling_37k/",level,"/",location,"-",Time,"_",level,".tsv")
        destfile_tmp=str_c(outfolder,"Downsampling/",level,"/",location,"-",Time,"_",level,".tsv")
        if(!file.exists(infile_tmp)){
        res <- tryCatch(download.file(infile_tmp, destfile_tmp, method="auto"), error=function(e) 1)
        }
      }
    }
  }
}

# iii Save new downsampling dataset if required
if (dsampling == 1){
  save(sampling, file = str_c(outfolder,"Downsampling/",date,"_sampling_",bcaller,"_",classifyr,".Rdata"))
}


# a. Create summary tables (on genus/family taxon level)
summary.genus <- matrix(NA, 3*12, 4)
colnames(summary.genus) <- c('Sampling depth', 'Sampling richness', 
                             'Richness at depth 37000X', 'Richness at depth 37000X (% orig.)')
rownames(summary.genus) <- sort(c(paste(names(sampling), '- 1April'), 
                                  paste(names(sampling), '- 2June'),
                                  paste(names(sampling), '- 3August')))
summary.genus <- summary.genus[c(1:30,34:36,31:33),]
rownames(summary.genus) <- gsub('1A|3A', 'A',rownames(summary.genus))
rownames(summary.genus) <- gsub('2J', 'J',rownames(summary.genus))
summary.family <- summary.genus
count <- 0
for (i in 1:12){
  for (j in 1:3){
    count <- count + 1
    
    # see if downsampling has already been done
    if(all(is.na(sampling[[i]][[j]]) == T)){next}
    summary.genus[count,1:2] <- as.numeric(sampling[[i]][[j]][nrow(sampling[[i]][[j]])-1,1:2])
    summary.family[count,1:2] <- as.numeric(sampling[[i]][[j]][nrow(sampling[[i]][[j]]),c(1,6)])

    if(summary.genus[count,1] > 37000){
      out <- mmfit(sampling[[i]][[j]], xlims = c(0,80000), type = 'genus')
      summary.genus[count,3] <- round(out$xy[which(out$xy[,1] == 37000),2],1)
      summary.genus[count,4] <- round(100*summary.genus[count,3]/summary.genus[count,2],1)
    }
    if(summary.family[count,1] > 37000){
      out <- mmfit(sampling[[i]][[j]], xlims = c(0,80000), type = 'family')
      summary.family[count,3] <- round(out$xy[which(out$xy[,1] == 37000),2],1)
      summary.family[count,4] <- round(100*summary.family[count,3]/summary.family[count,2],1)
    }
    
  }
}

# b. Repeat downsampling to fixed depth of 37,000 (on genus/family taxon level)
sample_classifications_single <- function(x, sample, n_rep, read_steps, min_reads){
  
  # a. pre-process
  x <- x[x[,sample,drop = F] >= min_reads,,drop = F]
  
  # b. run sampling function
  if(nrow(x) > 0){
    out <- sample_classifications(x = x[,c(1,sample)],
                                  n_rep = n_rep,
                                  read_steps = read_steps)
    out.stats <- cbind(read_steps, out$stats)
    colnames(out.stats) <- c('Depth', "Richness", "Shannon H", "Shannon E", 'Simpson D')
    return(list(stats = out.stats, sets = out$sets)) 
  }else{
    return(NA)
  }
  
}
genus.37000 <- vector(mode = 'list', length = 12)
names(genus.37000) <- c('1', '2', '3', '4', '5', '6', '7', '8', '9.1', '9.2', 'N', 'Mock')
family.37000 <- genus.37000
for (i in 1:length(sampling)){
  print(i)
  genus.37000[[i]] <- vector(mode = 'list', length = 3)
  names(genus.37000[[i]]) <- c("April", "June", "August")
  family.37000[[i]] <- genus.37000[[i]]
  for (j in 1:3){
    
    # see if downsampling has already been done
    barcode.name.tmp <- names(sampling)[i]
    out.ind <- grep(paste0('^',barcode.name.tmp,'$'), colnames(classifications.family[[j]]))
    if(length(out.ind) == 0){
      next
    }    
    genus.37000[[i]][[j]] <- sample_classifications_single(x = classifications.genus[[j]], 
                                                           sample = out.ind, 
                                                           n_rep = 100, 
                                                           read_steps = 37000,
                                                           min_reads = 5)
    
    family.37000[[i]][[j]] <- sample_classifications_single(x = classifications.family[[j]],
                                                            sample = out.ind, 
                                                            n_rep = 100, 
                                                            read_steps = 37000, 
                                                            min_reads = 5)
  }
}

# c. Output downsamplings as .TSVs
for (i in 1:12){
  print(i)
  for (j in 1:3){
    
    if(all(is.na(sampling[[i]][[j]]) == T) | nrow(sampling[[i]][[j]]) < 3){next}
    write.table(genus.37000[[i]][[j]]$sets, paste0(outfolder,'Downsampling/genus/', names(genus.37000)[i],'-', names(genus.37000[[i]])[j],'_genus.tsv'),
                quote = F, col.names = T, row.names = F, sep = '\t')
    
    write.table(family.37000[[i]][[j]]$sets, paste0(outfolder,'Downsampling/family/', names(family.37000)[i],'-', names(family.37000[[i]])[j],'_family.tsv'),
                quote = F, col.names = T, row.names = F, sep = '\t')
  }
}
```

### Rarefaction Plots for 16S classifications  
```{r}
# 2. Plotting functions
#######################

# a. Richness plots
richness.plots <- function(x, type, fixed.xmax, fixed.ymax, real.samples, title){
  
  # Define plot ranges
  if(fixed.xmax == ''){
    xlims <- c(0, max(x$April[,"Counts used"],
                      x$June[,"Counts used"],
                      x$August[,"Counts used"], na.rm = T))
  }else{
    xlims <- c(0, fixed.xmax)
  }
  
  if (type == "genus"){
    ind.richness <- 2
    ylabs <- 'Genera'
    
  }else if (type == "family"){
    ind.richness <- 6
    ylabs <- 'Families'
    
  }else if (type == "order"){
    ind.richness <- 10
    ylabs <- 'Orders'
    
  }else if (type == "class"){
    ind.richness <- 14
    ylabs <- 'Classes'
    
  }else if (type == "phylum"){
    ind.richness <- 18
    ylabs <- 'Phyla'
    
  }
  
  if(fixed.ymax == ''){
    ylims <- c(0, max(x$April[,ind.richness],
                      x$June[,ind.richness],
                      x$August[,ind.richness], na.rm = T)) 
  }else{
    ylims <- c(0, fixed.ymax)
  }
  
  ## Plot April
  plot(x = x$April[,"Counts used"],
       y = x$April[,ind.richness],
       ylab = ylabs, xlab = '', xaxt = 'n',
       pch = 16, type = 'p', col = 'goldenrod1', cex = 0.5,
       xlim = xlims, ylim = ylims,
       main = paste0(title, ": Richness"), cex.main = 3, cex.lab = 1.7, cex.axis = 1.3) 
  
  ## June
  points(x = x$June[,"Counts used"],
         y = x$June[,ind.richness],
         pch = 16,
         col = 'darkorange',
         type = 'p', cex = 0.5)
  
  ## August
  points(x = x$August[,"Counts used"],
         y = x$August[,ind.richness],
         pch = 16,
         col = 'red',
         type = 'p', cex = 0.5)
  
  axis(side = 1, at = seq(f = 0, t = xlims[2], length.out = 5), labels = seq(f = 0, t = xlims[2], length.out = 5))
  
  ## add Michaelis-Menten values
  if(type == 'genus'){
    
    if(x$April[c(nrow(x$April)-4),1] > 37000){
      mm.april <- mmfit(x = x$April, xlims = xlims, type = type)[[1]]
    }else{
      mm.april <- c()
    }
    if(x$June[c(nrow(x$June)-4),1] > 37000){
      mm.june <- mmfit(x = x$June, xlims = xlims, type = type)[[1]]
    }else{
      mm.june <- c()
    }
    if(x$August[c(nrow(x$August)-4),1] > 37000){
      mm.august <- mmfit(x = x$August, xlims = xlims, type = type)[[1]]
    }else{
      mm.august <- c()
    }
    
  }else if(type == 'family'){
    
    if(x$April[c(nrow(x$April)-3),1] > 37000){
      mm.april <- mmfit(x = x$April, xlims = xlims, type = type)[[1]]
    }else{
      mm.april <- c()
    }
    if(x$June[c(nrow(x$June)-3),1] > 37000){
      mm.june <- mmfit(x = x$June, xlims = xlims, type = type)[[1]]
    }else{
      mm.june <- c()
    }
    if(x$August[c(nrow(x$August)-3),1] > 37000){
      mm.august <- mmfit(x = x$August, xlims = xlims, type = type)[[1]]
    }else{
      mm.august <- c()
    }
    
  }else if(type == 'order'){
    
    if(x$April[c(nrow(x$April)-2),1] > 37000){
      mm.april <- mmfit(x = x$April, xlims = xlims, type = type)[[1]]
    }else{
      mm.april <- c()
    }
    if(x$June[c(nrow(x$June)-2),1] > 37000){
      mm.june <- mmfit(x = x$June, xlims = xlims, type = type)[[1]]
    }else{
      mm.june <- c()
    }
    if(x$August[c(nrow(x$August)-2),1] > 37000){
      mm.august <- mmfit(x = x$August, xlims = xlims, type = type)[[1]]
    }else{
      mm.august <- c()
    }
    
  }else if(type == 'class'){
    
    if(x$April[c(nrow(x$April)-1),1] > 37000){
      mm.april <- mmfit(x = x$April, xlims = xlims, type = type)[[1]]
    }else{
      mm.april <- c()
    }
    if(x$June[c(nrow(x$June)-1),1] > 37000){
      mm.june <- mmfit(x = x$June, xlims = xlims, type = type)[[1]]
    }else{
      mm.june <- c()
    }
    if(x$August[c(nrow(x$August)-1),1] > 37000){
      mm.august <- mmfit(x = x$August, xlims = xlims, type = type)[[1]]
    }else{
      mm.august <- c()
    }
    
  }else if(type == 'phylum'){
    
    if(x$April[nrow(x$April),1] > 37000){
      mm.april <- mmfit(x = x$April, xlims = xlims, type = type)[[1]]
    }else{
      mm.april <- c()
    }
    if(x$June[nrow(x$June),1] > 37000){
      mm.june <- mmfit(x = x$June, xlims = xlims, type = type)[[1]]
    }else{
      mm.june <- c()
    }
    if(x$August[nrow(x$August),1] > 37000){
      mm.august <- mmfit(x = x$August, xlims = xlims, type = type)[[1]]
    }else{
      mm.august <- c()
    }
    
  }
  
  ## replot actual scores
  if(real.samples != 'n'){
    
    if (type == "genus"){
      highest.april <- nrow(x$April)-4
      highest.june <- nrow(x$June)-4
      highest.august <- nrow(x$August)-4
    }else if (type == "family"){
      highest.april <- nrow(x$April)-3
      highest.june <- nrow(x$June)-3
      highest.august <- nrow(x$August)-3
    }else if (type == "order"){
      highest.april <- nrow(x$April)-2
      highest.june <- nrow(x$June)-2
      highest.august <- nrow(x$August)-2
    }else if (type == "class"){
      highest.april <- nrow(x$April)-1
      highest.june <- nrow(x$June)-1
      highest.august <- nrow(x$August)-1
    }else if (type == "phylum"){
      highest.april <- nrow(x$April)
      highest.june <- nrow(x$June)
      highest.august <- nrow(x$August)
    }
    
    points(x = x$April[highest.april,"Counts used"],
           y = x$April[highest.april,ind.richness],
           pch = 21,
           col = 'black',
           bg = 'goldenrod1',
           type = 'p', cex = 2)
    
    points(x = x$June[highest.june,"Counts used"],
           y = x$June[highest.june,ind.richness],
           pch = 21,
           col = 'black',
           bg = 'darkorange',
           type = 'p', cex = 2)
    
    points(x = x$August[highest.august,"Counts used"],
           y = x$August[highest.august,ind.richness],
           pch = 21,
           col = 'black',
           bg = 'red',
           type = 'p', cex = 2) 
    
  }
  
  legend.text <- c()
  legend.col <- c()
  if (length(mm.april) != 0){
    legend.text <- c(legend.text, paste0('April, Rmax: ', round(mm.april[1], 0)))
    legend.col <- c(legend.col, 'goldenrod1')
  }
  if (length(mm.june) != 0){
    legend.text <- c(legend.text, paste0('June, Rmax: ', round(mm.june[1], 0)))
    legend.col <- c(legend.col, 'darkorange')
  }
  if (length(mm.august) != 0){
    legend.text <- c(legend.text, paste0('August, Rmax: ', round(mm.august[1], 0)))
    legend.col <- c(legend.col, 'red')
  }
  if (length(legend.text) != 0){
    legend("topleft", legend = legend.text, lwd = 2, 
           pch = 16, col = legend.col, bty = 'n', cex = 1.2)  
  }
  
}
richness.plots.spec <- function(x, type, fixed.xmax, fixed.ymax, real.samples, col){
  
  # Define plot ranges
  if(fixed.xmax == ''){
    xlims <- c(0, max(x[,"Counts used"], na.rm = T))
  }else{
    xlims <- c(0, fixed.xmax)
  }
  
  if (type == "genus"){
    ind.richness <- 2
    ylabs <- 'Taxonomic Genera'
    
  }else if (type == "family"){
    ind.richness <- 6
    ylabs <- 'Taxonomic Families'
    
  }else if (type == "order"){
    ind.richness <- 10
    ylabs <- 'Taxonomic Orders'
    
  }else if (type == "class"){
    ind.richness <- 14
    ylabs <- 'Taxonomic Classes'
    
  }else if (type == "phylum"){
    ind.richness <- 18
    ylabs <- 'Taxonomic Phyla'
    
  }
  
  if(fixed.ymax == ''){
    ylims <- c(0, max(x[,ind.richness], na.rm = T)) 
  }else{
    ylims <- c(0, fixed.ymax)
  }
  
  # Plot
  plot(x = x[,"Counts used"],
       y = x[,ind.richness],
       ylab = ylabs, xlab = 'Sampling Depth', xaxt = 'n',
       pch = 16, type = 'p', col = col, cex = 0.5,
       xlim = xlims, ylim = ylims,
       main = "", cex.main = 2, 
       cex.lab = 1.5, cex.axis = 1.2)
  
  axis(side = 1, at = seq(f = 0, t = xlims[2], length.out = 6), labels = seq(f = 0, t = xlims[2], length.out = 6))
  
  ## replot actual scores
  if(real.samples != 'n'){
    
    if (type == "genus"){
      highest.april <- nrow(x$April)-4
      highest.june <- nrow(x$June)-4
      highest.august <- nrow(x$August)-4
    }else if (type == "family"){
      highest.april <- nrow(x$April)-3
      highest.june <- nrow(x$June)-3
      highest.august <- nrow(x$August)-3
    }else if (type == "order"){
      highest.april <- nrow(x$April)-2
      highest.june <- nrow(x$June)-2
      highest.august <- nrow(x$August)-2
    }else if (type == "class"){
      highest.april <- nrow(x$April)-1
      highest.june <- nrow(x$June)-1
      highest.august <- nrow(x$August)-1
    }else if (type == "phylum"){
      highest.april <- nrow(x$April)
      highest.june <- nrow(x$June)
      highest.august <- nrow(x$August)
    }
    
    points(x = x$April[highest.april,"Counts used"],
           y = x$April[highest.april,ind.richness],
           pch = 21,
           col = 'black',
           bg = 'goldenrod1',
           type = 'p', cex = 2)
    
    points(x = x$June[highest.june,"Counts used"],
           y = x$June[highest.june,ind.richness],
           pch = 21,
           col = 'black',
           bg = 'darkorange',
           type = 'p', cex = 2)
    
    points(x = x$August[highest.august,"Counts used"],
           y = x$August[highest.august,ind.richness],
           pch = 21,
           col = 'black',
           bg = 'red',
           type = 'p', cex = 2) 
    
  }
  
}

# b. Shannon evenness plots
shannon.plots <- function(x, type, fixed.xmax, real.samples, title){
  
  # Define plot ranges
  if(fixed.xmax == ''){
    xlims <- c(0, max(x$April[,"Counts used"],
                      x$June[,"Counts used"],
                      x$August[,"Counts used"], na.rm = T))
  }else{
    xlims <- c(0, fixed.xmax)
  }
  
  if (type == "genus"){
    ind.shannon <- 4
    ylabs <- 'Genera'
    
  }else if (type == "family"){
    ind.shannon <- 8
    ylabs <- 'Families'
    
  }else if (type == "order"){
    ind.shannon <- 12
    ylabs <- 'Orders'
    
  }else if (type == "class"){
    ind.shannon <- 16
    ylabs <- 'Classes'
    
  }else if (type == "phylum"){
    ind.shannon <- 20
    ylabs <- 'Phyla'
    
  }
  ylims <- c(0, 1)
  
  # Plot
  plot(x = x$April[,"Counts used"],
       y = x$April[,ind.shannon],
       ylab = '', xlab = '', xaxt = 'n',
       pch = 16, type = 'p', col = 'goldenrod1', cex = 0.5,
       xlim = xlims, ylim = ylims,
       main = paste0(title, ": Shannon Evenness"), cex.main = 3, 
       cex.lab = 1.7, cex.axis = 1.3)
  
  ## June
  points(x = x$June[,"Counts used"],
         y = x$June[,ind.shannon],
         pch = 16,
         col = 'darkorange',
         type = 'p', cex = 0.5)
  
  ## August
  points(x = x$August[,"Counts used"],
         y = x$August[,ind.shannon],
         pch = 16,
         col = 'red',
         type = 'p', cex = 0.5)
  
  axis(side = 1, at = seq(f = 0, t = xlims[2], length.out = 5), labels = seq(f = 0, t = xlims[2], length.out = 5))
  
  ## replot actual scores
  if(real.samples != 'n'){
    
    if (type == "genus"){
      highest.april <- nrow(x$April)-4
      highest.june <- nrow(x$June)-4
      highest.august <- nrow(x$August)-4
    }else if (type == "family"){
      highest.april <- nrow(x$April)-3
      highest.june <- nrow(x$June)-3
      highest.august <- nrow(x$August)-3
    }else if (type == "order"){
      highest.april <- nrow(x$April)-2
      highest.june <- nrow(x$June)-2
      highest.august <- nrow(x$August)-2
    }else if (type == "class"){
      highest.april <- nrow(x$April)-1
      highest.june <- nrow(x$June)-1
      highest.august <- nrow(x$August)-1
    }else if (type == "phylum"){
      highest.april <- nrow(x$April)
      highest.june <- nrow(x$June)
      highest.august <- nrow(x$August)
    }
    
    points(x = x$April[highest.april,"Counts used"],
           y = x$April[highest.april,ind.shannon],
           pch = 21,
           col = 'black',
           bg = 'goldenrod1',
           type = 'p', cex = 2)
    
    points(x = x$June[highest.june,"Counts used"],
           y = x$June[highest.june,ind.shannon],
           pch = 21,
           col = 'black',
           bg = 'darkorange',
           type = 'p', cex = 2)
    
    points(x = x$August[highest.august,"Counts used"],
           y = x$August[highest.august,ind.shannon],
           pch = 21,
           col = 'black',
           bg = 'red',
           type = 'p', cex = 2) 
    
  }
  
}

# c. Simpson's D evenness plots
simpson.plots <- function(x, type, fixed.xmax, real.samples, title){
  
  # Define plot ranges
  if(fixed.xmax == ''){
    xlims <- c(0, max(x$April[,"Counts used"],
                      x$June[,"Counts used"],
                      x$August[,"Counts used"], na.rm = T))
  }else{
    xlims <- c(0, fixed.xmax)
  }
  
  if (type == "genus"){
    ind.simpson <- 5
  }else if (type == "family"){
    ind.simpson <- 9
  }else if (type == "order"){
    ind.simpson <- 13
  }else if (type == "class"){
    ind.simpson <- 17
  }else if (type == "phylum"){
    ind.simpson <- 21
  }
  ylims <- c(0, 1)
  
  # Plot
  plot(x = x$April[,"Counts used"],
       y = x$April[,ind.simpson],
       ylab = '', xlab = '', xaxt = 'n',
       pch = 16, type = 'p', col = 'goldenrod1', cex = 0.5,
       xlim = xlims, ylim = ylims,
       main = paste0(title, ": Simpson's D"), cex.main = 3, 
       cex.lab = 1.7, cex.axis = 1.3)
  
  ## June
  points(x = x$June[,"Counts used"],
         y = x$June[,ind.simpson],
         pch = 16,
         col = 'darkorange',
         type = 'p', cex = 0.5)
  
  ## August
  points(x = x$August[,"Counts used"],
         y = x$August[,ind.simpson],
         pch = 16,
         col = 'red',
         type = 'p', cex = 0.5)
  
  axis(side = 1, at = seq(f = 0, t = xlims[2], length.out = 5), labels = seq(f = 0, t = xlims[2], length.out = 5))
  
  ## replot actual scores
  if(real.samples != 'n'){
    
    if (type == "genus"){
      highest.april <- nrow(x$April)-4
      highest.june <- nrow(x$June)-4
      highest.august <- nrow(x$August)-4
    }else if (type == "family"){
      highest.april <- nrow(x$April)-3
      highest.june <- nrow(x$June)-3
      highest.august <- nrow(x$August)-3
    }else if (type == "order"){
      highest.april <- nrow(x$April)-2
      highest.june <- nrow(x$June)-2
      highest.august <- nrow(x$August)-2
    }else if (type == "class"){
      highest.april <- nrow(x$April)-1
      highest.june <- nrow(x$June)-1
      highest.august <- nrow(x$August)-1
    }else if (type == "phylum"){
      highest.april <- nrow(x$April)
      highest.june <- nrow(x$June)
      highest.august <- nrow(x$August)
    }
    
    points(x = x$April[highest.april,"Counts used"],
           y = x$April[highest.april,ind.simpson],
           pch = 21,
           col = 'black',
           bg = 'goldenrod1',
           type = 'p', cex = 2)
    
    points(x = x$June[highest.june,"Counts used"],
           y = x$June[highest.june,ind.simpson],
           pch = 21,
           col = 'black',
           bg = 'darkorange',
           type = 'p', cex = 2)
    
    points(x = x$August[highest.august,"Counts used"],
           y = x$August[highest.august,ind.simpson],
           pch = 21,
           col = 'black',
           bg = 'red',
           type = 'p', cex = 2) 
  }
}

# 3. Supplementary Figure: rarefaction effects on the Family level
##################################################################

pdf(str_c(outfolder,'Downsampling/',date,'_Supplementary_Figure_rarefactions.pdf'),
    width = 18, height = 7)
par(mfrow = c(1,2))
par(mar = c(7, 6, 5, 2))

## part A
richness.plots.spec(x = sampling[[1]]$April, type = 'family', 
                    fixed.xmax = 100000, fixed.ymax = 160, real.samples = 'n', col = '#2157A4')
abline(v = 37000, lty = 2, lwd = 0.5)

## part B
sampling.cols <- c('#2157A4', '#3694D1', '#65C6E8', '#9DD7ED', '#F7EC73', 
                   '#FDCB44', '#F1861E', '#E63A11', '#D61015', '#D61015')
names(sampling.cols) <- c(1, 2, 3, 4, 5, 6, 7, 8, 9.1, 9.2)

## summarise richnesses at 37000X [you can add/remove samples here!]
tmp.rich <- cbind(family.37000$`1`$April$stats[,2],
                  family.37000$`1`$June$stats[,2],
                  family.37000$`1`$August$stats[,2],
                  family.37000$`2`$April$stats[,2],
                  family.37000$`2`$August$stats[,2], #
                  family.37000$`3`$April$stats[,2],
                  family.37000$`4`$April$stats[,2],
                  family.37000$`4`$August$stats[,2], #
                  family.37000$`5`$April$stats[,2],
                  family.37000$`5`$August$stats[,2],
                  family.37000$`6`$June$stats[,2],
                  family.37000$`6`$August$stats[,2],
                  family.37000$`7`$April$stats[,2],
                  family.37000$`8`$April$stats[,2],
                  family.37000$`9.1`$August$stats[,2],
                  family.37000$`9.2`$August$stats[,2])
colnames(tmp.rich) <- c('1 - April', 
                        '1 - June', 
                        '1 - August', 
                        '2 - April', 
                        '2 - August', 
                        '3 - April',
                        '4 - April', 
                        '4 - August', 
                        '5 - April', 
                        '5 - August', 
                        '6 - June', 
                        '6 - August',
                        '7 - April', 
                        '8 - April', 
                        '9.1 - August', 
                        '9.2 - August')

## fetch original richnesses
#genus.richness.orig <- summary.genus[match(colnames(tmp.rich), rownames(summary.genus)),2]
family.richness.orig <- summary.family[match(colnames(tmp.rich), rownames(summary.family)),2]

## obtain ratios and percentage values
for (i in 1:ncol(tmp.rich)){
  tmp.rich[,i] <- 100*c(tmp.rich[,i]/family.richness.orig[i])
}

## match colors in plot
col.match <- str_split_fixed(colnames(tmp.rich), ' - ', 2)[,1]
cols <- as.character(sampling.cols[match(col.match,names(sampling.cols))])

boxplot(tmp.rich,
        main = "", 
        cex.main = 2, ylab = 'Original richness at 37,000 X [%]', ylim = c(0, 100), 
        cex.lab = 1.5, cex.axis = 1, 
        pch = 16, cex = 0.3, notch = T, las = 2, yaxt = 'n',
        col = cols, 
        border = cols)
axis(2, at = seq(f = 0, t = 100, by = 20), las = 3, cex.axis = 1.2)
dev.off()


# 4. Three additional Figures (feel free to remove them)
########################################################

cols.all <- c(rep('#2157A4', 3), rep('#3694D1', 3), rep('#65C6E8', 3),
              rep('#9DD7ED', 3), rep('#F7EC73', 3), rep('#FDCB44', 3),
              rep('#F1861E', 3), rep('#E63A11', 3), rep('#D61015', 3), 
              rep('#D61015', 3), rep('grey', 3), rep('black', 3))

# a. Downsampling effects on richness and evenness for all samples
# pdf(outfolder,'Downsampling/',date,'_final_sampling_',classifyr,'_downsampling_richness_vs_evenness.pdf', 
#     width = 18, height = 7)
# par(mfcol = c(1,2))
# #for(type in c('genus', 'family', 'order', 'class', 'phylum')){
# for(type in c('family')){
# 
#   if(type == 'genus'){
#     fixed.ymax = 1000
#   }else if(type == 'family'){
#     fixed.ymax = 300
#   }else if(type == 'order'){
#     fixed.ymax = 250
#   }else if(type == 'class'){
#     fixed.ymax = 100
#   }else if(type == 'phylum'){
#     fixed.ymax = 50
#   }
#   
#   for (i in 1:12){
#     par(mar = c(4, 6, 4, 3))
#     richness.plots(x = sampling[[i]], type = type, fixed.xmax = 80000, fixed.ymax = fixed.ymax, real.samples = 'n',
#                    title = names(sampling)[i])
#     abline(v = 37000, lty = 2, lwd = 0.5)
#     shannon.plots(x = sampling[[i]], type = type, fixed.xmax = 80000, real.samples = 'n',
#                   title = names(sampling)[i])
#     abline(v = 37000, lty = 2, lwd = 0.5)
#   }  
# }
# dev.off()

# b. Original sequencing depths vs. 37,000 reads cutoff
pdf(str_c(outfolder,'Downsampling/',date,'_final_sampling_',classifyr,'_depth_cutoff_37000X.pdf'), 
    width = 8, height = 6)
# barplot(summary.genus[,1], las = 2, col = cols.all, border = cols.all, ylim = c(0,1000000), 
#         main = 'Original read depth (Genus)', cex.main = 2, cex.names = 0.7)
# abline(h = 37000, lty = 2)
barplot(summary.family[,1], las = 2, col = cols.all, border = cols.all, ylim = c(0,2000000), 
        main = 'Original read depth (Family)', cex.main = 2, cex.names = 0.7, cex.axis = 0.7)
abline(h = 37000, lty = 2)
# barplot(summary.order[,1], las = 2, col = cols.all, border = cols.all, ylim = c(0,1000000), 
#         main = 'Original read depth (Order)', cex.main = 2, cex.names = 0.7)
# abline(h = 37000, lty = 2)
# barplot(summary.class[,1], las = 2, col = cols.all, border = cols.all, ylim = c(0,1000000), 
#         main = 'Original read depth (Class)', cex.main = 2, cex.names = 0.7)
# abline(h = 37000, lty = 2)
# barplot(summary.phylum[,1], las = 2, col = cols.all, border = cols.all, ylim = c(0,1000000),
#         main = 'Original read depth (Phylum)', cex.main = 2, cex.names = 0.7)
# abline(h = 37000, lty = 2)
dev.off()

# c. Correlation of original sequencing depth vs. richness at 37000X
pdf(str_c(outfolder,'Downsampling/',date,'_final_sampling_',classifyr,'_richness_at_37000X_vs_sampling_depth.pdf'), width = 8, height = 6)

## Genus
plot(x = summary.family[1:30,1],
     y = summary.family[1:30,3], 
     pch = 16, 
     xlab = 'Original sampling Depth',
     ylab = 'Family richness at 37,000X',
     xlim = c(0,1000000),
     ylim = c(0,300), col = cols.all[1:30], 
     main = 'Family richness vs. 16S read depth', cex.main = 2)
pearson.cor <- round(cor(summary.family[1:30,1], summary.family[1:30,3], use = 'complete.obs'),3)
lm.out <- summary(lm(summary.family[1:30,3] ~ summary.family[1:30,1]))
pval <- round(lm.out[[4]][2,4],3)
abline(coef = lm.out[[4]][,1], lty = 2)
legend('topright', c(paste('Pearson correlation: ', pearson.cor),
                     paste('LM p-value: ', pval)))

# 
# ## Order
# plot(x = summary.order[1:30,1],
#      y = summary.order[1:30,3], 
#      pch = 16, 
#      xlab = 'Original sampling Depth',
#      ylab = 'Order richness at 37,000X',
#      xlim = c(0,1000000),
#      ylim = c(0,250), col = cols.all[1:30], 
#      main = 'Order richness vs. 16S read depth', cex.main = 2)
# pearson.cor <- round(cor(summary.order[1:30,1], summary.order[1:30,3], use = 'complete.obs'),3)
# lm.out <- summary(lm(summary.order[1:30,3] ~ summary.order[1:30,1]))
# pval <- round(lm.out[[4]][2,4],3)
# abline(coef = lm.out[[4]][,1], lty = 2)
# legend('topright', c(paste('Pearson correlation: ', pearson.cor),
#                      paste('LM p-value: ', pval)))
# 
# ## Class
# plot(x = summary.class[1:30,1],
#      y = summary.class[1:30,3], 
#      pch = 16, 
#      xlab = 'Original sampling Depth',
#      ylab = 'Class richness at 37,000X',
#      xlim = c(0,1000000),
#      ylim = c(0,100), col = cols.all[1:30], 
#      main = 'Class richness vs. 16S read depth', cex.main = 2)
# pearson.cor <- round(cor(summary.class[1:30,1], summary.class[1:30,3], use = 'complete.obs'),3)
# lm.out <- summary(lm(summary.class[1:30,3] ~ summary.class[1:30,1]))
# pval <- round(lm.out[[4]][2,4],3)
# abline(coef = lm.out[[4]][,1], lty = 2)
# legend('topright', c(paste('Pearson correlation: ', pearson.cor),
#                      paste('LM p-value: ', pval)))
# 
# ## Phylum
# plot(x = summary.phylum[1:30,1],
#      y = summary.phylum[1:30,3], 
#      pch = 16, 
#      xlab = 'Original sampling Depth',
#      ylab = 'Phylum richness at 37,000X',
#      xlim = c(0,1000000),
#      ylim = c(0,50), col = cols.all[1:30], 
#      main = 'Phylum richness vs. 16S read depth', cex.main = 2)
# pearson.cor <- round(cor(summary.phylum[1:30,1], summary.phylum[1:30,3], use = 'complete.obs'),3)
# lm.out <- summary(lm(summary.phylum[1:30,3] ~ summary.phylum[1:30,1]))
# pval <- round(lm.out[[4]][2,4],3)
# abline(coef = lm.out[[4]][,1], lty = 2)
# legend('topright', c(paste('Pearson correlation: ', pearson.cor),
#                      paste('LM p-value: ', pval)))
dev.off()
```

### *(Please check: AttributeError: 'DataFrame' object has no attribute 'taxRank', adjust directory of output files) Pull single downsampling datasets (and three replicates) for downstream analysis
This section is only nessesary if a new subsampling should be performed.
```{python, eval=FALSE}
<!-- import datetime -->
<!-- import pandas as pd  -->
<!-- import io -->
<!-- import os -->
<!-- import requests -->
<!-- import numpy as np -->

<!-- DATE = datetime.datetime.now().strftime('%Y-%m-%d') -->
<!-- outfolder = DATE + '_PuntSeq_Downstream-metagenomics-analysis/' -->
<!-- bcaller = 'Guppy' -->
<!-- classifyr = 'minimap' -->

<!-- # build and save exemplar rarefaction dataframes  -->
<!-- data = pd.read_csv(outfolder+'Downsampling/genus/%s' % os.listdir(outfolder+'Downsampling/genus/')[0], sep='\t', index_col=0, header=0) -->
<!-- data = data[~data.index.duplicated(keep='first')] -->
<!-- data = data[data.taxRank == 'G'] -->
<!-- del data['taxRank'] -->
<!-- datacolumns = [os.listdir(outfolder+'Downsampling/genus/')[0]] -->
<!-- for filename in os.listdir(outfolder+'Downsampling/genus/')[1:]: -->
<!--     if filename.endswith(".tsv"): -->
<!--         data0 = pd.read_csv(outfolder+'Downsampling/genus/%s' %filename, sep='\t', index_col=0, header=0) -->
<!--         data0 = data0[~data0.index.duplicated(keep='first')] -->
<!--         data0 = data0[data0.taxRank == 'G'] -->
<!--         del data0['taxRank'] -->
<!--         data = pd.concat([data,data0], axis=1) -->
<!--         datacolumns.append(filename) -->

<!-- # choose samples with more than 37k reads in the full dataset to keep for downstream analyses   -->
<!-- url = "https://raw.githubusercontent.com/d-j-k/puntseq/master/analysis/data/Analysis_bioRxiv/"+bcaller+"/April_"+classifyr+".tsv" -->
<!-- s = requests.get(url).content -->
<!-- full1 = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='\t', index_col=0, header=0) -->
<!-- full1 = full1[~full1.index.duplicated(keep='first')] -->
<!-- full1 = full1[full1.taxRank=='G'] -->
<!-- full1.iloc[:,3:15].sum()  -->

<!-- url = "https://raw.githubusercontent.com/d-j-k/puntseq/master/analysis/data/Analysis_bioRxiv/"+bcaller+"/June_"+classifyr+".tsv" -->
<!-- s = requests.get(url).content -->
<!-- full2 = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='\t', index_col=0, header=0) -->
<!-- full2 = full2[~full2.index.duplicated(keep='first')] -->
<!-- full2 = full2[full2.taxRank=='G'] -->
<!-- full2.iloc[:,3:15].sum()  -->

<!-- url = "https://raw.githubusercontent.com/d-j-k/puntseq/master/analysis/data/Analysis_bioRxiv/"+bcaller+"/August_"+classifyr+".tsv" -->
<!-- s = requests.get(url).content -->
<!-- full3 = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='\t', index_col=0, header=0) -->
<!-- full3 = full3[~full3.index.duplicated(keep='first')] -->
<!-- full3 = full3[full3.taxRank=='G']     -->
<!-- full3.iloc[:,3:15].sum()  -->

<!-- # choose samples >37k -->
<!-- datacolumns_filt = ['1-April_genus.tsv', -->
<!--  '1-August_genus.tsv', -->
<!--  '1-June_genus.tsv', -->
<!--  '2-April_genus.tsv', -->
<!--  '2-August_genus.tsv', -->
<!--  '3-April_genus.tsv', -->
<!--  '4-April_genus.tsv', -->
<!--  '4-August_genus.tsv', -->
<!--  '5-April_genus.tsv', -->
<!--  '5-August_genus.tsv', -->
<!--  '6-August_genus.tsv', -->
<!--  '6-June_genus.tsv', -->
<!--  '7-April_genus.tsv', -->
<!--  '8-April_genus.tsv', -->
<!--  '9.1-August_genus.tsv', -->
<!--  '9.2-August_genus.tsv', -->
<!--  'Mock-April_genus.tsv', -->
<!--  'Mock-August_genus.tsv', -->
<!--  'Mock-June_genus.tsv', -->
<!--  'N-August_genus.tsv'] -->

<!-- posfilt = [np.where(np.array(datacolumns) == x)[0][0] for x in datacolumns_filt] -->

<!-- # create four exemplar rarefaction dataframes for later comparison; we will mostly work with "final_1.tsv" -->
<!-- for nr in ['1','2','3','4']: -->
<!--     dataa = data.copy() -->
<!--     dataa = dataa[nr] -->
<!--     dataa = dataa.dropna(how='all') -->
<!--     dataa = dataa.fillna(0) -->
<!--     dataa = dataa.iloc[:,posfilt] -->
<!--     dataa.columns = datacolumns_filt -->
<!--     dataa.to_csv(outfolder+'Downsampling/genus/final_%s.tsv' %nr, sep='\t') -->
```

### *Mantel test
```{python}

```

##  Download/load downsampled classifier output data
```{r eval=FALSE}
# loop over all downsampling sets of both family and genus level
for (set in 1:4){
  for (level in c("family","genus")){
    
    # download and original downsampling files if nessesary
    if (dsampling == 0){
      # download downsampled datasets
      infile_downsampling<-str_c("https://raw.githubusercontent.com/d-j-k/puntseq/master/minimap2/downsampled/final_",level,"_",set,".tsv") 
      destfile_downsampling=str_c(outfolder,"Downsampling/",level,"/Downsampled_",level,"_set",set,"_",classifyr,".tsv")
      if(!file.exists(destfile_downsampling)){
        res <- tryCatch(download.file(infile_downsampling, destfile_downsampling, method="auto"), error=function(e) 1)
      }
    # else refer to new downsampled data files 
    } else {
      destfile_downsampling=str_c(outfolder,"Downsampling/",level,"/final_",level,"_",set,".tsv")
    }
    
    # define variable name
    var_name <- paste("classified_reads_downsampled_",level,"_set", set, sep = "")
    # assign data to variable
    assign(var_name, read_tsv(destfile_downsampling))
    
  }
}

# load downsampled datasets into lists
family.list <- list(classified_reads_downsampled_family_set1, classified_reads_downsampled_family_set2, classified_reads_downsampled_family_set3, classified_reads_downsampled_family_set4)
genus.list <- list(classified_reads_downsampled_genus_set1, classified_reads_downsampled_genus_set2, classified_reads_downsampled_genus_set3, classified_reads_downsampled_genus_set4)

# combine lists into a single multidimensional list
classified_reads_downsampled <- list(family.list, genus.list)
```

## Rawdata overview plots
### Pie charts of total reads per barcode for each MinION run
```{r eval=FALSE}
# Create output directory
system(str_c("mkdir ",outfolder,"Overview-plots/"))

# Load data into dataframe and prepare for plotting
reads.data.raw <- read_tsv(str_c(outfolder,"Metadata/Metadata_guppy_minimap2_table2.txt"))
reads.data <- select(reads.data.raw, Barcode, Date, Reads, Reads_percent) %>%
  mutate(Date = str_replace(Date, pattern = "15.04.2018", "April")) %>%
  mutate(Date = str_replace(Date, pattern = "17.06.2018", "June")) %>%
  mutate(Date = str_replace(Date, pattern = "19.08.2018", "August")) %>%
  rename(barcode = Barcode) %>%
  rename(time = Date) %>%
  rename(n = Reads) %>%
  rename(perc = Reads_percent)

# Add label position
reads.data <- reads.data %>%
  mutate(lab.ypos = cumsum(perc) - 0.5*perc)

# Pie chart version 1
ggplot(reads.data, aes(x = "", y = perc, fill = barcode)) +
  geom_bar(width = 1, stat = "identity", color = "white") +
  coord_polar("y", start = 0)+
  facet_grid(cols = vars(time))+ 
  geom_text(aes(label = paste0(round(perc), "%")), position = position_stack(vjust = 0.5), color = "white")+
  scale_fill_manual(values = lcolors) +
  theme_void()+
  theme(legend.position="right")

# save plot
ggsave(str_c(outfolder,"Overview-plots/",date,"_total_reads_per_barcod_",classifyr,"_1.png"), width = 20, height = 10, units = "cm")
ggsave(str_c(outfolder,"Overview-plots/",date,"_total_reads_per_barcod_",classifyr,"_1.pdf"), width = 20, height = 10, units = "cm") 

# Pie chart version 2
ggplot(reads.data, aes(x = 2, y = perc, fill = barcode)) +
  geom_bar(stat = "identity", color = "white") +
  coord_polar(theta = "y", start = 0)+
  facet_grid(cols = vars(time))+ 
  geom_text(aes(label = paste0(round(perc), "%")), position = position_stack(vjust = 0.5), color = "white")+
  scale_fill_manual(values = lcolors) +
  theme_void()+
  xlim(0.5, 2.5)+
  theme(legend.position="right")

# save plot
ggsave(str_c(outfolder,"Overview-plots/",date,"_total_reads_per_barcod_",classifyr,"_2.png"), width = 20, height = 10, units = "cm")
ggsave(str_c(outfolder,"Overview-plots/",date,"_total_reads_per_barcod_",classifyr,"_2.pdf"), width = 20, height = 10, units = "cm") 
```

### Correlation analysis for DNA concentration and read numbers
```{r eval=FALSE}
# Load data  from metadata file into dataframe and prepare for plotting
DNA.data.raw <- read_tsv(str_c(outfolder,"Metadata/Metadata_guppy_minimap2_table2.txt"))
DNA.data <- DNA.data.raw %>%
  mutate(Date = str_replace(Date, pattern = "15.04.2018", "April")) %>%
  mutate(Date = str_replace(Date, pattern = "17.06.2018", "June")) %>%
  mutate(Date = str_replace(Date, pattern = "19.08.2018", "August")) %>%
  transform(DNA_Concentration = as.numeric(DNA_Concentration)) %>%
  transform(DNA_Total = as.numeric(DNA_Total))  %>%
  rename(Time = Date)

# Correlation between DNA yield and PCR yield
 p1 <- ggscatter(DNA.data, x = "DNA_Concentration", y = "X16S_Concentration", xticks.by = 10)+
   geom_point(aes(color=Time))+
   scale_color_grey()+
   labs(title = "", caption = waiver(), x="DNA concentration (ng/l)", y="16S concentration (ng/l)")+
   geom_smooth(se = TRUE, method = "lm", formula = y ~ x, color = "black")+
   stat_cor(label.x = 2,label.y = 45, size = 4, method = "pearson", col="black") +           # Add correlation coefficient
   theme(legend.position="right")

 # Correlation between PCR yield and sequencing output
p2 <- ggscatter(DNA.data, x = "X16S_Concentration", y = "Reads", yscale = "log10")+
  geom_point(aes(color=Time))+
  labs(title = "", caption = waiver(), x="16S concentration (ng/l)", y="Reads (1)")+
  scale_color_grey()+
  scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),
                     labels = trans_format("log10", math_format(10^.x)))+
  annotation_logticks(sides="l")+
  geom_smooth(se = TRUE, method = "gam", formula = y ~ s(log(x)), color = "black")+
  stat_poly_eq(aes(color = Time, label = ..eq.label..), formula = y ~ s(log(x)), label.y = 0.9, label.x = 0.05, size = 2.5,parse = TRUE) +
  geom_vline(aes(xintercept=4), color="red",linetype="dashed")+
  theme(legend.position="top")

# combine both plots 
ggarrange(
  p1, p2, labels = c("A", "B"), ncol = 2, nrow = 1,
  common.legend = TRUE, legend = "right"
  )

# save plot
ggsave(str_c(outfolder,"Overview-plots/",date,"_Correlation_plots_DNA-vs-PCR-vs-Reads.png"), width = 22, height = 10, units = "cm")
ggsave(str_c(outfolder,"Overview-plots/",date,"_Correlation_plots_DNA-vs-PCR-vs-Reads.pdf"), width = 22, height = 10, units = "cm") 
```

# Part 2: Global analysis
## Tidying & cleaning data for plotting
Within the next lines of code, raw data is tidied up and prepared for plotting. Full dataset containing all reads obtained as well as downsampled datasets are processed. 

### Full dataset
Data from April:
```{r eval=FALSE}
# read in family data
classified_reads_april_family <- read_tsv(destfile_april_family)
classified_reads_april_family <- rename(classified_reads_april_family, Name = X1) %>%
    mutate(TaxRank = "F")

# read in genus data
classified_reads_april_genus <- read_tsv(destfile_april_genus)
classified_reads_april_genus <- rename(classified_reads_april_genus, Name = X1) %>%
    mutate(TaxRank = "G")

# combine family and genus data
classified_reads_april <- rbind(classified_reads_april_family, classified_reads_april_genus)

# tidy data and extract absolute read numbers
tidy_classified_reads_april <- gather(classified_reads_april, key = "Location", value = "Reads", 2:13)%>%
  mutate(Time = "April") %>%
  mutate(Classifyer = classifyr)

# calculate percentage
total_read_number_april <- 
  hash(keys=colnames(classified_reads_april[2:13]),
  values=colSums(classified_reads_april[2:13]))

for (i in 1:nrow(tidy_classified_reads_april)){
    tidy_classified_reads_april$Percentage[i] <- tidy_classified_reads_april$Reads[i]/total_read_number_april [[tidy_classified_reads_april$Location[i]]]*100
  }

# clean and order dataset
clean_classified_reads_april <- select(tidy_classified_reads_april, Name, TaxRank, Location, Time, Classifyer, Reads, Percentage) %>%
  mutate_at(vars(TaxRank,Location,Time,Classifyer),list(factor))

clean_classified_reads_april # display cleaned data table
```

Data from June:
```{r eval=FALSE}
# read in family data
classified_reads_june_family <- read_tsv(destfile_june_family)
classified_reads_june_family <- rename(classified_reads_june_family, Name = X1) %>%
    mutate(TaxRank = "F")

# read in genus data
classified_reads_june_genus <- read_tsv(destfile_june_genus)
classified_reads_june_genus <- rename(classified_reads_june_genus, Name = X1) %>%
    mutate(TaxRank = "G")

# combine family and genus data
classified_reads_june <- rbind(classified_reads_june_family, classified_reads_june_genus)

# tidy data and extract absolute read numbers
tidy_classified_reads_june <- gather(classified_reads_june, key = "Location", value = "Reads", 2:13)%>%
  mutate(Time = "June") %>%
  mutate(Classifyer = classifyr)

# calculate percentage
total_read_number_june <- 
  hash(keys=colnames(classified_reads_june[2:13]),
  values=colSums(classified_reads_june[2:13]))

for (i in 1:nrow(tidy_classified_reads_june)){
    tidy_classified_reads_june$Percentage[i] <- tidy_classified_reads_june$Reads[i]/total_read_number_june [[tidy_classified_reads_june$Location[i]]]*100
  }

# clean and order dataset
clean_classified_reads_june <- select(tidy_classified_reads_june, Name, TaxRank, Location, Time, Classifyer, Reads, Percentage) %>%
  mutate_at(vars(TaxRank,Location,Time,Classifyer),list(factor))

clean_classified_reads_june # display cleaned data table
```
Data from August:
```{r eval=FALSE}
# read in family data
classified_reads_august_family <- read_tsv(destfile_august_family)
classified_reads_august_family <- rename(classified_reads_august_family, Name = X1) %>%
    mutate(TaxRank = "F")

# read in genus data
classified_reads_august_genus <- read_tsv(destfile_august_genus)
classified_reads_august_genus <- rename(classified_reads_august_genus, Name = X1) %>%
    mutate(TaxRank = "G")

# combine family and genus data
classified_reads_august <- rbind(classified_reads_august_family, classified_reads_august_genus)

# tidy data and extract absolute read numbers
tidy_classified_reads_august <- gather(classified_reads_august, key = "Location", value = "Reads", 2:13)%>%
  mutate(Time = "August") %>%
  mutate(Classifyer = classifyr)

# calculate percentage
total_read_number_august <- 
  hash(keys=colnames(classified_reads_august[2:13]),
  values=colSums(classified_reads_august[2:13]))

for (i in 1:nrow(tidy_classified_reads_august)){
    tidy_classified_reads_august$Percentage[i] <- tidy_classified_reads_august$Reads[i]/total_read_number_august [[tidy_classified_reads_august$Location[i]]]*100
  }

# clean and order dataset
clean_classified_reads_august <- select(tidy_classified_reads_august, Name, TaxRank, Location, Time, Classifyer, Reads, Percentage) %>%
  mutate_at(vars(TaxRank,Location,Time,Classifyer),list(factor))

clean_classified_reads_august # display cleaned data table
```
Combining data of all three time points:
```{r eval=FALSE}
clean_classified_reads <- bind_rows(clean_classified_reads_april, clean_classified_reads_june, clean_classified_reads_august)%>%
  transform( Time = factor(Time, levels = c("April","June","August")))

classified_reads_root <- read_tsv(destfile_root)
clean_classified_reads <-rbind(clean_classified_reads, classified_reads_root)

clean_classified_reads # display combined data table

```

### Downsampled data
Similar to the full datasets, the sets of downsampled data are prepared for plotting. 
```{r eval=FALSE}

# Initialise lists
list1 <- list("","","","")
list2 <- list("","","","")
tidy_classified_reads_downsampled <- list(list1,list2)
clean_classified_reads_downsampled <- list(list1,list2)

# loop over all 4 downsampling sets and bot family and genus levels
for (set in 1:4){
  for (level in 1:2){
    if(level == 1){
      # create hashs of taxon classification and associated number of reads
      total_read_number <- hash(keys=colnames(classified_reads_downsampled[[level]][[set]][2:21]), values=colSums(classified_reads_downsampled[[level]][[set]][2:21]))
      # convert dataframe so that factors can be used for plotting    
      tidy_classified_reads_downsampled[[level]][[set]] <- gather(classified_reads_downsampled[[level]][[set]], key = "Location", value = "Reads", 2:21)
    }  else {
      # create hashs of taxon classification and associated number of reads
      total_read_number <- hash(keys=colnames(classified_reads_downsampled[[level]][[set]][2:19]), values=colSums(classified_reads_downsampled[[level]][[set]][2:19]))
      # convert dataframe so that factors can be used for plotting
      tidy_classified_reads_downsampled[[level]][[set]] <- gather(classified_reads_downsampled[[level]][[set]], key = "Location", value = "Reads", 2:19)
    }
   
    # calculate and add percentage
    for (i in 1:nrow(tidy_classified_reads_downsampled[[level]][[set]])){
      tidy_classified_reads_downsampled[[level]][[set]]$Percentage[i] <- tidy_classified_reads_downsampled[[level]][[set]]$Reads[i]/total_read_number [[tidy_classified_reads_downsampled[[level]][[set]]$Location[i]]]*100
    }
    
    # clean dataframe
    clean_classified_reads_downsampled[[level]][[set]] <- separate(tidy_classified_reads_downsampled[[level]][[set]], Location, into = c("Location","Time"), sep="-") %>%
      separate(Time, into = c("Time","TaxRank"), sep="_") %>%
      mutate(TaxRank = str_replace(TaxRank, pattern = "family.tsv", "F")) %>%
      mutate(TaxRank = str_replace(TaxRank, pattern = "genus.tsv", "G")) %>%
      mutate(Info = str_c("downsampled ",classifyr)) %>%
      mutate_at(vars(TaxRank,Location,Time,Info),funs(factor))
    
    colnames(clean_classified_reads_downsampled[[level]][[set]])[colnames(clean_classified_reads_downsampled[[level]][[set]]) == "X1"] <- "Name"
  }  
}
```

## Plotting data
### Reads per location/time point
Next, the distribution of reads per location/time point is displayed in a barchart.
```{r eval=FALSE}
# Create output directory
system(str_c("mkdir ",outfolder,"Overview-plots/"))

subset1<- filter(clean_classified_reads, Name == "root" | Name == "unclassified") %>%
  mutate( Name = str_replace(Name, pattern = "root", "classified")) %>%
  transform( Name = factor(Name, levels = c("unclassified","classified")))

# Overview plot: total number of reads per location
ggplot(data = subset1, mapping = aes(x = Location, y = Reads, fill = Time))+
  geom_bar(stat="identity", width = 0.7, position ="dodge", colour = "black")+
  labs(title = "Number of reads per location/time point")+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5, face="bold.italic"))+
  theme(legend.title = element_blank())+
  scale_y_continuous(labels = scientific_1)+
  scale_fill_manual(values = tcolors) +
  theme(axis.line.x = element_blank())+
  theme(axis.ticks.x = element_blank())

# save plot
ggsave(str_c(outfolder,"Overview-plots/",date,"_Number-of-reads-per-location-time-point_",classifyr,".png"), width = 20, height = 15, units = "cm")
ggsave(str_c(outfolder,"Overview-plots/",date,"_Number-of-reads-per-location-time-point_",classifyr,".pdf"), width = 20, height = 15, units = "cm")
```

### Number of classified/unclassified reads per location/time point
Next, the distribution of classified/unclassified reads per location/time point is displayed.
```{r eval=FALSE}
# create a subset of the dataframe for plotting
subset2<- filter(clean_classified_reads, Name == "root" | Name == "unclassified") %>%
  mutate( Name = str_replace(Name, pattern = "root", "classified")) %>%
  transform( Name = factor(Name, levels = c("unclassified","classified"))) %>%
  mutate( Location = str_replace(Location, pattern = "Mock", "P"))

# Overview: Distribution of classified vs. unclassified reads per location and time point
ggplot(data = subset2, mapping = aes(x = Location, y = Reads, fill = Name))+
  geom_bar(stat="identity", width = 0.7)+
  facet_wrap(~Time)+
  geom_hline(aes(yintercept=37000, color="Downsampling"), linetype="dashed")+
  labs(title = "Distribution of classified vs. unclassified reads per location and time point")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 11))+
  theme(axis.text.x = element_text(size = 7))+
  theme(axis.text.y = element_text(size = 7))+
  theme(legend.text = element_text(size = 8))+
  theme(legend.title = element_blank())+
  scale_fill_manual(values=c("#999999","#56B4E9"))+
  scale_y_continuous(labels = scientific_1)

ggsave(str_c(outfolder,"Overview-plots/",date,"_Distribution-of-classified-unclassified-reads-per-location-time-point_V1_",classifyr,".png"), width = 20, height = 15, units = "cm")
ggsave(str_c(outfolder,"Overview-plots/",date,"_Distribution-of-classified-unclassified-reads-per-location-time-point_V1_",classifyr,".pdf"), width = 20, height = 15, units = "cm") 

# Zoom in: Distribution of classified vs. unclassified reads per location and time point
ggplot(data = subset2, mapping = aes(x = Location, y = Reads, fill = Name))+
  geom_bar(stat="identity", width = 0.7)+
  facet_wrap(~Time)+
  geom_hline(aes(yintercept=37000, color="Downsampling"), linetype="dashed")+
  labs(title = "Zoom in: Distribution of classified vs. unclassified reads per location and time point")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 11))+
  theme(axis.text.x = element_text(size = 7))+
  theme(axis.text.y = element_text(size = 7))+
  theme(legend.text = element_text(size = 8))+
  theme(legend.title = element_blank())+
  scale_fill_manual(values=c("#999999","#56B4E9"))+
  coord_cartesian(ylim = c(0,80000))+
  scale_y_continuous(labels = scientific_1)

# save plot
ggsave(str_c(outfolder,"Overview-plots/",date,"_Distribution-of-classified-unclassified-reads-per-location-time-point_V2_",classifyr,".png"), width = 20, height = 15, units = "cm")
ggsave(str_c(outfolder,"Overview-plots/",date,"_Distribution-of-classified-unclassified-reads-per-location-time-point_V2_",classifyr,".pdf"), width = 20, height = 15, units = "cm") 

# Distribution of normalized numbers of classified/unclassified reads per sample location
ggplot(data = subset2, mapping = aes(x = Location, y = Percentage, fill = Name))+
  geom_bar(stat="identity", width = 0.7)+
  facet_wrap(~Time)+  
  labs(title = "Percentage of classified vs. unclassified reads per location and time point", y = "% Reads")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 11))+
  theme(axis.text.x = element_text(size = 8))+
  theme(axis.text.y = element_text(size = 7))+
  theme(legend.text = element_text(size = 8))+
  theme(legend.title = element_blank())+
  scale_fill_manual(values=c("#999999","#56B4E9"))

# save plot
ggsave(str_c(outfolder,"Overview-plots/",date,"_Percentage-of-classified-unclassified-reads-per-location-time-point_",classifyr,".png"), width = 20, height = 15, units = "cm")
ggsave(str_c(outfolder,"Overview-plots/",date,"_Percentage-of-classified-unclassified-reads-per-location-time-point_",classifyr,".pdf"), width = 20, height = 15, units = "cm") 
```

### Number of classified reads per taxonomic level (Supplementary Figure)
The number of reads classified onto the different taxonomic levels was displayed using the followiung code:
```{r eval=FALSE}
# Filtering and adjutsing data for plotting
subset3_1 <- filter(clean_classified_reads) %>% 
  mutate(TaxRank = as.character(TaxRank)) %>%
  mutate(TaxRank = ifelse(Name == "root", "R", TaxRank)) %>%
  mutate(TaxRank = factor(TaxRank, levels = c("U","R","D","P","C","O","F","G","K","-")))

subset3_2 <- subset3_1 %>%
  filter(TaxRank != "-" & TaxRank != "K" ) %>%
  filter(!is.na(Reads)) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "C", "Class")) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "R", "Classified")) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "U", "Unclassified")) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "D", "Domain")) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "P", "Phylum")) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "O", "Order")) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "F", "Family")) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "G", "Genus")) %>%
  group_by(TaxRank, Location, Time) %>%
  summarize(Sum = sum(Reads))%>%
  ungroup(TaxRank, Location, Time)

subset3_3 <- filter(subset3_1, TaxRank == "R" | TaxRank == "U" ) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "R", "Classified")) %>%
  mutate( TaxRank = str_replace(TaxRank, pattern = "U", "Unclassified")) %>%
  filter(!is.na(Reads)) %>%
  group_by(Location, Time) %>%
  summarize(Sum = sum(Reads)) %>%
  mutate(TaxRank = "Total")

subset3_4 <- full_join(subset3_2, subset3_3, by = c("TaxRank", "Location", "Time", "Sum"))

subset3_4 <- filter(subset3_4, TaxRank != "Unclassified") %>%
  mutate(Location = factor(Location)) %>%
  mutate(TaxRank = factor(TaxRank, levels = c("Total","Classified","Domain","Phylum","Class","Order","Family","Genus"), ordered = TRUE))

for (setting in c("samples","samples+controls")){
  if (setting == "samples"){
    subset3_5 <- filter(subset3_4, Location != "N" & Location != "P")
  } else {
    subset3_5 <- mutate(subset3_4, Location = str_replace(Location, pattern = "Mock", "P"))
  }
  
  # Number of classified reads per taxonomic level
  ggplot(data = subset3_5, mapping = aes(x = Location, y = Sum, fill = TaxRank))+
    geom_bar(stat="identity",position = position_dodge(), width = 0.7)+
    facet_grid(cols = vars(Time))+ 
    geom_hline(yintercept=37000, linetype="dashed", color = "black")+
    labs(title = "Number of classified reads per taxonomic level",y = "Reads (1)")+
    theme_bw()+
    theme(plot.title = element_text(hjust = 0.5, size = 22))+
    theme(axis.text.x = element_text(size = 16))+
    theme(axis.text.y = element_text(size = 14))+
    theme(legend.text = element_text(size = 16))+
    theme(legend.title = element_blank())+
    scale_fill_grey()+
    scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),
                       labels = trans_format("log10", math_format(10^.x)))+
    annotation_logticks(sides="l")
  
  # save plots
  ggsave(str_c(outfolder,"Overview-plots/",date,"_Number-of-classified-reads-per-taxonomic-level_",classifyr,"_",setting,".png"), width = 30, height = 15, units = "cm")
  ggsave(str_c(outfolder,"Overview-plots/",date,"_Number-of-classified-reads-per-taxonomic-level_",classifyr,"_",setting,".pdf"), width = 30, height = 15, units = "cm") 
}
```

### Relative abundance: Representation on the different taxonomic levels
The relative species abundance on the different taxonomic levels was visualised using the following lines of code. 
#### Full dataset
```{r eval=FALSE}
# create output directory
system(str_c("mkdir ",outfolder,"Relatve_abundance"))
system(str_c("mkdir ",outfolder,"Relatve_abundance/Full-dataset/"))
system(str_c("mkdir ",outfolder,"Relatve_abundance/Full-dataset/Total"))
system(str_c("mkdir ",outfolder,"Relatve_abundance/Full-dataset/Top10-per-sample"))
system(str_c("mkdir ",outfolder,"Relatve_abundance/Full-dataset/Top10-highest-single-abundance"))
system(str_c("mkdir ",outfolder,"Relatve_abundance/Full-dataset/Top10-highest-total-abundance"))

# define color vector for plots
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
col_vector_3 = c(col_vector,col_vector,col_vector)
#pie(rep(1,60), col=sample(col_vector, 60)) # to visualise color vector

# make plots for all samples as well as samples+controls
for (setting in c("samples","samples+controls")){
  
  # loop over all taxonomic ranks
  ranks <- c("family","genus")
  ranks_plural <- c("families","genera")
  rank_i <- 0
  
  for (rank in c("F","G")){
    rank_i <- rank_i + 1
    subset_rank<- filter(clean_classified_reads, TaxRank == rank, Percentage != "NA")%>%  
      mutate( Location = str_replace(Location, pattern = "Mock", "P")) %>%
      arrange(desc(Percentage))
    
    # filter subset of data so that only the samples or samples + controls are plotted
    if (setting == "samples"){
      subset_rank_1 <- filter(subset_rank, Location != "N" & Location != "P")
    } else {
      subset_rank_1 <- subset_rank
    }
    
    # Where we at?
    print(paste0('Processing data of ', setting,' - on ', ranks[rank_i], ' level'))
    
    # a. plot relativ adunance showing all taxa for ranks = "D" || "P" || "C"
    if (rank == "D" || rank == "P" || rank == "C" ) {
      
      ggplot(data = subset_rank_1, mapping = aes(x = Location, y = Percentage, fill = Name))+
          geom_bar(stat="identity",  position = "fill", width = 0.8)+
          facet_wrap(~Time)+  
          labs(title = str_c("Relativ abundance on ",ranks[rank_i]," level"), y = "Abundance")+
          theme_bw()+
          theme(plot.title = element_text(hjust = 0.5, size = 11))+
          theme(axis.text.x = element_text(size = 8))+
          theme(axis.text.y = element_text(size = 7))+
          theme(legend.text = element_text(size = 8))+
          theme(legend.title = element_blank())+
          scale_fill_manual(values = col_vector_3)
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Total/",date,"_Relative-abundance-plot_Total_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,".pdf"), width = 50, height = 20, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Total/",date,"_Relative-abundance-plot_Total_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,".png"), width = 50, height = 20, units = "cm")
    } 
    
    # for all taxa for ranks != "D" 
    if (rank != "D") {
      
      # b. select top 10 most abundant taxa per sample
      subset_rank_top10<- subset_rank_1 %>%
        arrange(Time) %>%
        arrange(Location) %>%
        unite_("Location_Time", c("Location","Time"))%>%
        group_by(Location_Time)
      subset_rank_top10_top <- slice(subset_rank_top10, -11:-n())
      subset_rank_top10_bottom <- slice(subset_rank_top10, 11:n()) %>%
        mutate( Name = "Other")
      subset_rank_top10 <- bind_rows(subset_rank_top10_top, subset_rank_top10_bottom)%>%
        separate(Location_Time, into = c("Location","Time"), sep="_")%>%
        transform( Time = factor(Time, levels = c("April","June","August"))) 
      
      legend <- subset_rank_top10$Name %>%
        unique()
      legend <- fct_relevel(legend, "Other", after = 0L)
      subset_rank_top10 <- transform(subset_rank_top10, Name = factor(Name, levels = legend))
      
      # plot relativ abundance showing the top 10 most abundant taxa per sample for ranks != "D"
      ggplot(data = subset_rank_top10, mapping = aes(x = Location, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Time)+  
        labs(title = str_c("Top 10 most abundant ",ranks_plural[rank_i]," per sample"), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = col_vector)
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-per-sample/",date,"_Relative-abundance-plot_Top10_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,".pdf"), width = 30, height = 15, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-per-sample/",date,"_Relative-abundance-plot_Top10_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,".png"), width = 30, height = 15, units = "cm")
      
      
      # c. select top 10 most abundant taxa with the highest single abundance (in percent) among all samples
      legend <- subset_rank_1$Name %>%
        unique()
      legend <- c(legend[1:10], "Other")
      subset_rank_top10_2 <- transform(subset_rank_1, Name = factor(Name, levels = legend)) %>%
        mutate(Name = replace_na(Name, "Other")) %>%
        transform( Time = factor(Time, levels = c("April","June","August"))) 
    
      # plot relativ abundance (Version 1) showing the top 10 most abundant taxa with the highest single abundance (in percent) among all samples
      ggplot(data = subset_rank_top10_2, mapping = aes(x = Location, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Time)+  
        labs(title = str_c("Most abundant ",ranks_plural[rank_i]), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,"_V1.pdf"), width = 30, height = 15, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,"_V1.png"), width = 30, height = 15, units = "cm")
    
      # plot relativ abundance (Version 2) showing the top 10 most abundant taxa with the highest single abundance (in percent) among all samples
      ggplot(data = subset_rank_top10_2, mapping = aes(x = Time, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Location)+  
        labs(title = str_c("Most abundant ",ranks_plural[rank_i]), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,"_V2.pdf"), width = 30, height = 25, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,"_V2.png"), width = 30, height = 25, units = "cm")
     
      
      # d. select top 10 most abundant taxa with the highest total abundance (percentage) among all samples
       subset_tmp <- subset_rank_1 %>%
        group_by(Name) %>%
        summarize(Sum = sum(Percentage)) %>%
        ungroup(Name) %>%
        arrange(desc(Sum))
      legend <- subset_tmp$Name %>%
        unique()
      legend <- c(legend[1:10], "Other")
      subset_rank_top10_3 <- transform(subset_rank_1, Name = factor(Name, levels = legend)) %>%
        mutate(Name = replace_na(Name, "Other")) %>%
        transform( Time = factor(Time, levels = c("April","June","August"))) 
    
      # plot relativ abundance (Version 1) showing the top 10 most abundant taxa with the highest total abundance (percentage) among all samples
      ggplot(data = subset_rank_top10_3, mapping = aes(x = Location, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Time)+  
        labs(title = str_c("Most abundant ",ranks_plural[rank_i]), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Total-Most-abundant_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,"_V1.pdf"), width = 30, height = 15, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Total-Most-abundant_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,"_V1.png"), width = 30, height = 15, units = "cm")
    
      # plot relativ abundance (Version 2) showing the top 10 most abundant taxa with the highest total abundance (percentage) among all samples
      ggplot(data = subset_rank_top10_3, mapping = aes(x = Time, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Location)+  
        labs(title = str_c("Most abundant ",ranks_plural[rank_i]), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Total-Most-abundant_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,"_V2.pdf"), width = 30, height = 25, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Full-dataset/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Total-Most-abundant_level-",rank_i,"_",ranks[rank_i],"_",classifyr,"_",setting,"_V2.png"), width = 30, height = 25, units = "cm")
    }
  }
}
```

#### Downsampled data
```{r eval=FALSE}
# create general output directories
system(str_c("mkdir ",outfolder,"Relatve_abundance"))
system(str_c("mkdir ",outfolder,"Relatve_abundance/Downsampled-dataset/"))
system(str_c("mkdir ",outfolder,"Relatve_abundance/Downsampled-dataset/family"))
system(str_c("mkdir ",outfolder,"Relatve_abundance/Downsampled-dataset/genus"))

# for each of the downsampling datasets poduced 
for (set in 1:4){
  for (level in 1:2){
  
    if (level == 1){
      rank <- "F"                 
      rank_i <- 5                 
      ranks <- "Family"            
      ranks_plural <- "families"     
    } else {
      rank <- "G"                  
      rank_i <- 6                 
      ranks <- "Genus"            
      ranks_plural <- "genera"     
    }
    
    # create specific output directories
    system(str_c("mkdir ",outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set))
    system(str_c("mkdir ",outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-per-sample"))
    system(str_c("mkdir ",outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-single-abundance"))
    system(str_c("mkdir ",outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-total-abundance"))
    
    # define color vector for plots
    qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
    col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
    col_vector_3 = c(col_vector,col_vector,col_vector)
    #pie(rep(1,60), col=sample(col_vector, 60)) # to visualise color vector
    
    # make plots for all samples as well as samples+controls
    for (setting in c("samples","samples+controls")){
      
      # Where we at?
      print(paste0('Processing downsampled data set ',set,' on ', ranks,' level, for ', setting))
      
      subset_rank<- filter(clean_classified_reads_downsampled[[level]][[set]], TaxRank == rank, Percentage != "NA")%>%  
        #filter(!grepl('Eukaryota', Linage)) %>% # select only bacterial taxa by filterin out eukaryotic taxa below domain level
        #filter(!grepl('Archaea', Linage)) %>% # select only bacterial taxa by filterin out archaea taxa below domain level
        mutate( Location = str_replace(Location, pattern = "Mock", "P")) %>%
        arrange(desc(Percentage))
        
      # filter subset of data so that only the samples or samples + controls are plotted
      if (setting == "samples"){
        subset_rank_1 <- filter(subset_rank, Location != "N" & Location != "P")
      } else {
        subset_rank_1 <- subset_rank
      }
          
      # a. select top 10 most abundant taxa per sample
      subset_rank_top10<- subset_rank_1 %>% 
        arrange(Time) %>%
        arrange(Location) %>%
        unite_("Location_Time", c("Location","Time"))%>%
        group_by(Location_Time)
      subset_rank_top10_top <- slice(subset_rank_top10, -11:-n())
      subset_rank_top10_bottom <- slice(subset_rank_top10, 11:n()) %>%
        mutate( Name = "Other")
      subset_rank_top10 <- bind_rows(subset_rank_top10_top, subset_rank_top10_bottom)%>%
        separate(Location_Time, into = c("Location","Time"), sep="_")%>%
        transform( Time = factor(Time, levels = c("April","June","August"))) 
        
      legend <- subset_rank_top10$Name %>%
        unique()
      legend <- fct_relevel(legend, "Other", after = 0L)
      subset_rank_top10 <- transform(subset_rank_top10, Name = factor(Name, levels = legend))
        
      # plot relativ abundance showing the top 10 most abundant taxa per sample for ranks != "D"
      ggplot(data = subset_rank_top10, mapping = aes(x = Location, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Time)+  
        labs(title = str_c("Top 10 most abundant ",ranks_plural," per sample"), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = col_vector)
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-per-sample/",date,"_Relative-abundance-plot_Top10_level",rank_i,"_",ranks,"_",classifyr,"_",setting,".pdf"), width = 30, height = 15, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-per-sample/",date,"_Relative-abundance-plot_Top10_level",rank_i,"_",ranks,"_",classifyr,"_",setting,".png"), width = 30, height = 15, units = "cm")
          
          
      # b. select top 10 most abundant taxa with the highest single abundance (in percent) among all samples
      legend <- subset_rank_1$Name %>%
        unique()
      legend <- c(legend[1:10], "Other")
      subset_rank_top10_2 <- transform(subset_rank_1, Name = factor(Name, levels = legend)) %>%
          mutate(Name = replace_na(Name, "Other")) %>%
          transform( Time = factor(Time, levels = c("April","June","August"))) 
    
      # plot relativ abundance (Version 1) showing the top 10 most abundant taxa with the highest single abundance (in percent) among all samples
      ggplot(data = subset_rank_top10_2, mapping = aes(x = Location, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Time)+  
        labs(title = str_c("Most abundant ",ranks_plural), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V1.pdf"), width = 30, height = 15, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V1.png"), width = 30, height = 15, units = "cm")
      
      # plot relativ abundance (Version 2) showing the top 10 most abundant taxa with the highest single abundance (in percent) among all samples
      ggplot(data = subset_rank_top10_2, mapping = aes(x = Time, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Location)+  
        labs(title = str_c("Most abundant ",ranks_plural), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V2.pdf"), width = 30, height = 25, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V2.png"), width = 30, height = 25, units = "cm")
        
      # shorten annotation for August
      subset_rank_top10_2_1 <- subset_rank_top10_2 %>%
        mutate(Time = str_replace(Time, pattern = "August", "Aug")) %>%
        transform(Time = factor(Time, levels = c("April","June","Aug"), ordered = TRUE))
      
      # plot relativ abundance (Version 3) showing the top 10 most abundant taxa with the highest single abundance (in percent) among all samples
      ggplot(data = subset_rank_top10_2_1, mapping = aes(x = Time, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity", position = "fill", width = 0.4)+
        facet_grid(cols = vars(Location))+ 
        labs(title = str_c("Most abundant ",ranks_plural), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 22))+
        theme(axis.text.x = element_text(size = 16))+
        theme(axis.text.y = element_text(size = 14))+
        theme(legend.text = element_text(size = 16))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plot
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V3.pdf"), width = 60, height = 15, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-single-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V3.png"), width = 60, height = 15, units = "cm")
        
      
      # c. select top 10 most abundant taxa with the highest total abundance (percentage) among all samples
      subset_tmp <- subset_rank_1 %>%
        group_by(Name) %>%
        summarize(Sum = sum(Percentage)) %>%
        ungroup(Name) %>%
        arrange(desc(Sum))
      legend <- subset_tmp$Name %>%
        unique()
      legend <- c(legend[1:10], "Other")
      subset_rank_top10_3 <- transform(subset_rank_1, Name = factor(Name, levels = legend)) %>%
        mutate(Name = replace_na(Name, "Other")) %>%
        transform( Time = factor(Time, levels = c("April","June","August"))) 
      
      # plot relativ abundance (Version 1) showing the top 10 most abundant taxa with the highest total abundance (percentage) among all samples
      ggplot(data = subset_rank_top10_3, mapping = aes(x = Location, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Time)+  
        labs(title = str_c("Most abundant ",ranks_plural), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Total-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V1.pdf"), width = 30, height = 15, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Total-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V1.png"), width = 30, height = 15, units = "cm")
        
      # plot relativ abundance (Version 2) showing the top 10 most abundant taxa with the highest total abundance (percentage) among all samples
      ggplot(data = subset_rank_top10_3, mapping = aes(x = Time, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity",  position = "fill", width = 0.8)+
        facet_wrap(~Location)+  
        labs(title = str_c("Most abundant ",ranks_plural), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 11))+
        theme(axis.text.x = element_text(size = 8))+
        theme(axis.text.y = element_text(size = 7))+
        theme(legend.text = element_text(size = 8))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plots
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Total-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V2.pdf"), width = 30, height = 25, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Total-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V2.png"), width = 30, height = 25, units = "cm")
      
      # shorten annotation for August
      subset_rank_top10_3_1 <- subset_rank_top10_3 %>%
        mutate(Time = str_replace(Time, pattern = "August", "Aug")) %>%
        transform(Time = factor(Time, levels = c("April","June","Aug"), ordered = TRUE))
      
      # plot relativ abundance (Version 3) the top 10 most abundant taxa with the highest total abundance (percentage) among all samples
      ggplot(data = subset_rank_top10_3_1, mapping = aes(x = Time, y = Percentage, fill = forcats::fct_rev(Name)))+
        geom_bar(stat="identity", position = "fill", width = 0.4)+
        facet_grid(cols = vars(Location))+ 
        labs(title = str_c("Most abundant ",ranks_plural), y = "Abundance")+
        theme_bw()+
        theme(plot.title = element_text(hjust = 0.5, size = 22))+
        theme(axis.text.x = element_text(size = 16))+
        theme(axis.text.y = element_text(size = 14))+
        theme(legend.text = element_text(size = 16))+
        theme(legend.title = element_blank())+
        scale_fill_manual(values = rev(brewer.pal(11,"Set3")))
      # save plot
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V3.pdf"), width = 60, height = 15, units = "cm")
      ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-total-abundance/",date,"_Relative-abundance-plot_Individual-Most-abundant_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,"_V3.png"), width = 60, height = 15, units = "cm")
      
      
      # for the first downsampling set
      if (set == 1){
        
        # extract information about total number of reads assigned to the top 10 most abundant families
        subset_rank_info <- subset(subset_rank_top10_3, select = c(Name, Location, Time, Reads)) %>%
          mutate(Name = ifelse(Name != "Other", str_c("10 most abundant ",ranks_plural), str_c("Other ",ranks_plural)))%>%
          group_by(Name, Location, Time) %>%
          summarize(Sum = sum(Reads)) %>%
          ungroup(Name, Location, Time) 
        
        # use helper dataframes to set all unexiting values in subset_rank_info to 0
        help_subset_1 <- subset(subset3_4, select = c(Location, Time)) %>%
          group_by(Location, Time) %>%
          unique()%>%
          mutate(Name = str_c("10 most abundant ",ranks_plural))
        help_subset_2 <- subset(subset3_4, select = c(Location, Time)) %>%
          group_by(Location, Time) %>%
          unique()%>%
          mutate(Name = str_c("Other ",ranks_plural))
        help_subset <- rbind(help_subset_1 , help_subset_2) %>%
          ungroup(Location, Time) %>%
          mutate(Location = as.character(Location)) %>%
          mutate( Location = str_replace(Location, pattern = "Mock", "P"))
        
        # join helper dataframe with info dataframe to get NA values
        subset_rank_info <- right_join(subset_rank_info, help_subset) 
        
        # extract information about number of total reads, number of classified reads & number of on family level classified reads
        subset_rank_2 <- subset(subset3_4, select = c(TaxRank, Location, Time, Sum)) %>%
          filter(TaxRank == "Total" | TaxRank == "Classified" | TaxRank == ranks) %>%
          rename(Name = TaxRank) %>%
          mutate( Location = str_replace(Location, pattern = "Mock", "P"))
        
        # combine both dataframes and order factors for plotting
        subset_rank_3 <- rbind(subset_rank_2, subset_rank_info) %>%
          transform(Name = factor(Name, levels = c("Total","Classified",ranks,str_c("10 most abundant ",ranks_plural),str_c("Other ",ranks_plural)), ordered = TRUE)) %>%
          mutate(Time = str_replace(Time, pattern = "August", "Aug")) %>%
          transform(Time = factor(Time, levels = c("April","June","Aug"), ordered = TRUE))
        
        # filter subset of data so that only the samples or samples + controls are plotted
        if (setting == "samples"){
          subset_rank_3  <- filter(subset_rank_3 , Location != "N" & Location != "P")
        }
        
        # plot number of reads for the different levels (Total, classified, family/genus, 10 most abundant families/genera, Other families/genera) 
        ggplot(data = subset_rank_3, mapping = aes(x = Time, y = Sum, fill = Name))+
          geom_bar(stat="identity", position = position_dodge(), width = 0.7)+
          facet_grid(cols = vars(Location))+ 
          geom_hline(yintercept=37000, linetype="dashed", color = "black")+
          labs(title = "Level of Classifiation",y = "Reads (1)")+
          theme_bw()+
          theme(plot.title = element_text(hjust = 0.5, size = 22))+
          theme(axis.text.x = element_text(size = 16))+
          theme(axis.text.y = element_text(size = 14))+
          theme(legend.text = element_text(size = 16))+
          theme(legend.title = element_blank())+
          scale_fill_manual(values=c("#636363","#bdbdbd","#d9d9d9","#56B4E9","#ccebc5"))+
          scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
          annotation_logticks(sides="l")
        # save plot
        ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-total-abundance/",date,"_Read-numbers-in-comparison_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,".pdf"), width = 60, height = 15, units = "cm")
        ggsave(str_c(outfolder,"Relatve_abundance/Downsampled-dataset/",ranks,"/Set",set,"/Top10-highest-total-abundance/",date,"_Read-numbers-in-comparison_level-",rank_i,"_",ranks,"_",classifyr,"_",setting,".png"), width = 60, height = 15, units = "cm") 
      }
    }
  }
}
```
### Clustering & visualisation as heatmap 
you just apply log10 at the moment, right? I would (afterwards) standardize the features by removing the mean and scaling to unit variance to give each bacteria the same "chance" of showing outliers - does that make sense?) 
```{r eval=FALSE}

# create output directory
system(str_c("mkdir ",outfolder,"Heatmap"))
system(str_c("mkdir ",outfolder,"Heatmap/Downsampled-dataset/"))

# loop over all 4 downsampling sets
for (set in 1:4){
  
  # create specific output directories
  system(str_c("mkdir ",outfolder,"Heatmap/Downsampled-dataset/Set",set))

  # generate plots for downsampled data on genus and family level
  for (rank in c("family","genus")) {
    
    # Where we at?
    print(paste0('Processing downsampled data set ',set,' - on ',rank,' level'))
    
    # define input data depending in rank level
    if (rank == "family"){
      data.tmp <- filter(clean_classified_reads_downsampled[[1]][[set]], TaxRank == "F", Reads != "NA")%>%
      unite("Colnames", c("Location","Time"), sep = " - ") %>%
      select(Name, Colnames, Reads) %>%
      spread(key = Colnames, value = Reads)
    }
      
    if (rank == "genus"){
      data.tmp <- filter(clean_classified_reads_downsampled[[2]][[set]], TaxRank == "G", Reads != "NA")%>%
      unite("Colnames", c("Location","Time"), sep = " - ") %>%
      select(Name, Colnames, Reads) %>%
      spread(key = Colnames, value = Reads)
    } 
    
    # initialise data matrix for heatmap
    heatmap <- as.matrix(as.data.frame(data.tmp))
    rownames(heatmap) <- heatmap[,1]
    heatmap <- heatmap[,-1]
    class(heatmap) <- "numeric"
    
    # NA entries -> 0 entries
    heatmap[is.na(heatmap)] <- 0
    
    # remove rows (i.e. taxa) in which all entries -> 0
    heatmap <- heatmap[!apply(heatmap, 1, function(x) {all(x == 0)}),]
    
    # permform Log10(x+1) data transformation
    heatmap <- log10(heatmap+1)
    
    # make plots for all samples as well as samples+controls
    for (setting in c("samples","samples+controls")){
      if (setting == "samples"){
        heatmap_1 <- heatmap[,1:(ncol(heatmap)-4)]
      } else {
        heatmap_1 <- heatmap[,1:(ncol(heatmap)-1)]
      }
      
      # prepare annotations for histogram
      gAnnotationData <- colnames(heatmap_1)
      gAnnotationData <- tibble(gAnnotationData, .name_repair = ~ c("Name"))
      gAnnotationData$Location <- gAnnotationData$Name
      gAnnotationData <- gAnnotationData %>%
        separate(Location, into = c("Location","Time"), sep="-")
      gAnnotationData$Location <- trimws(gAnnotationData$Location)
      gAnnotationData$Time<- trimws(gAnnotationData$Time)
      
      gAnnotationData1 <- select(gAnnotationData, Location)%>%
        mutate(Location = str_replace(Location, pattern = "9.1", "9")) %>%
        mutate(Location = str_replace(Location, pattern = "9.2", "9"))
      gAnnotationData1$Location <- as_factor(gAnnotationData1$Location)
      gAnnotationData1<-as.data.frame(gAnnotationData1)
      row.names(gAnnotationData1) <- colnames(heatmap_1)
      
      gAnnotationData2 <- select(gAnnotationData, Location, Time)%>%
        mutate(Location = str_replace(Location, pattern = "9.1", "9")) %>%
        mutate(Location = str_replace(Location, pattern = "9.2", "9"))
      gAnnotationData1$Location <- as_factor(gAnnotationData1$Location)
      gAnnotationData2$Time <- as_factor(gAnnotationData2$Time)
      gAnnotationData2<-as.data.frame(gAnnotationData2)
      row.names(gAnnotationData2) <- colnames(heatmap_1)
      
      # define colors
      my_colour = list(
        Location = c("1" = "#2157A4", "2" = "#3694D1", "3" = "#65C6E8", "4" = "#9DD7ED", "5" = "#F7EC73", "6" = "#FDCB44", "7" = "#F1861E", "8" = "#E63A11", "9" = "#D61015", "Mock" = "#636363", "N" = "#f0f0f0"),
        Time = c("April" = "#66c2a5", "June" = "#fc8d62", "August" = "#8da0cb"),
        Cluster = c("C1" = "#bdbdbd", "C2" = "#969696", "C3" = "#737373", "C4" = "#525252"))
      
       # perform hirachical clustering and devide taxa into 4 cluster
      my_hclust_gene <- hclust(dist(heatmap_1), method = "complete")
      as.dendrogram(my_hclust_gene) %>%
        plot(horiz = TRUE)
      my_gene_col <- cutree(tree = as.dendrogram(my_hclust_gene), k = 4)
      my_gene_col <- data.frame(Cluster = ifelse(test = my_gene_col == 1, yes = "C1", no = ifelse(test = my_gene_col == 2, yes = "C2", no= ifelse(test = my_gene_col == 3, yes = "C3", no = "C4"))))
      
      # plot heatmap
      my_heatmap <- pheatmap(heatmap_1, 
        clustering_distance_cols = "correlation",
        #clustering_distance_rows = "correlation",
        color = colorRampPalette(brewer.pal(n = 7, name = "Greens"))(100),
        show_rownames = FALSE, show_colnames = FALSE,
        annotation_row = my_gene_col,
        annotation_col = gAnnotationData2,
        annotation_colors = my_colour,
        cutree_rows = 4,
        cutree_cols = 2)
      
      # define function to save heatmap in .png format
      save_pheatmap_png <- function(x, filename, width=2000, height=2000, res = 300) {
        png(filename, width = width, height = height, res = res)
        grid::grid.newpage()
        grid::grid.draw(x$gtable)
        dev.off()
      }
      
      # define function to save heatmap in .pdf format
      save_pheatmap_pdf <- function(x, filename, width=7, height=7) {
        stopifnot(!missing(x))
        stopifnot(!missing(filename))
        pdf(filename, width=width, height=height)
        grid::grid.newpage()
        grid::grid.draw(x$gtable)
        dev.off()
      }
      
      # save heatmap in both .png & .pdf file format
      save_pheatmap_png(my_heatmap, str_c(outfolder,"Heatmap/Downsampled-dataset/Set",set,"/",date,"_heatmap_downsampled_set-",set,"_",rank,"-level_",setting,".png"))
      save_pheatmap_pdf(my_heatmap, str_c(outfolder,"Heatmap/Downsampled-dataset/Set",set,"/",date,"_heatmap_downsampled_set-",set,"_",rank,"-level_",setting,".pdf"))
      
      # save cluster mapping
      cluster.mapping <- rownames_to_column(my_gene_col, var = "Name")
      save(cluster.mapping ,file = file.path(str_c(outfolder,"Heatmap/Downsampled-dataset/Set",set,"/",date,"_cluster-mapping_downsampled_set-",set,"_",rank,"-level_",setting,".RData")))
    }
  }    
}
```

### Core microbiome
```{r eval=FALSE}
# create output directory
system(str_c("mkdir ",outfolder,"Core_microbiome"))

# loop over family and genus downsampling datasets
for (rank in c("family","genus")) {
  if (rank == "family"){
    i <- 1
    Rank <- "F"
  } else {
    i <- 2
    Rank <- "G"
  }

  # loop over all 4 downsampling datasets
  for (set in 1:4){
    
    # Where we at?
    print(paste0('Processing downsampled data set ',set,' on ', rank,' level.'))
    
    # Prepare data for annotation 
    selection <- filter(clean_classified_reads_downsampled[[i]][[set]], TaxRank == Rank, Percentage != "NA", Location != "N" & Location != "Mock" & Location != "P") %>%
      mutate(Set = set)
  
    if (set == 1){
      core.microbiome <- selection
    } else {
      core.microbiome <- rbind(core.microbiome, selection)
    }
  }
  
  core.microbiome <- core.microbiome %>%
    group_by(Name) %>%
    mutate(Median = median(Percentage)) %>%
    ungroup(Name) %>%
    arrange(desc(Median)) %>%
    filter(Median > 0.1)
  
  # add clutster information from downsampling set1
  load(file.path(str_c(outfolder,"Heatmap/Downsampled-dataset/Set1/",date,"_cluster-mapping_downsampled_set-1_",rank,"-level_samples+controls.RData")))
  core.microbiome <- left_join(core.microbiome, cluster.mapping)
  core.microbiome <- transform(core.microbiome, Cluster = factor(Cluster, levels = c("C4","C2","C3","C1"))) %>%
    transform(core.microbiome, Time = factor(Time, levels = c("April","June","August"))) 
  
  for (setting in c("all.clusters","core.clusters")){
    if (setting == "core.clusters"){
      core.microbiome <- filter(core.microbiome, Cluster != "C1" & Cluster != "C3") 
    }
  
    ggplot(core.microbiome,aes(x=reorder(Name, Percentage, FUN = median),y=Percentage)) +
    #geom_jitter(aes(colour = Location),show.legend = FALSE)+
    geom_boxplot(color = "black",fill="grey",show.legend = FALSE) +
    #geom_jitter(position=position_jitter(0.01)) +
    #geom_col(aes(y = 0.01, fill = Cluster), width = 0.9) + 
    facet_grid(cols = vars(Time), rows = vars(Cluster), scales = "free_y",space = "free_y")+ #cols = vars(Time),
    #coord_trans(y="log10")+
    #scale_colour_grey(start=0.8, end=0.2)+
    #scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    #scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    #geom_hline(yintercept=10, linetype="dashed", color = "black")+
    scale_y_continuous(name ="Percentage", trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
    #annotation_logticks(sides="l")+
    coord_flip()+
    theme_minimal()+
    theme(axis.ticks = element_blank())+
    xlab("")
    
    # save plots
    ggsave(str_c(outfolder,"Core_microbiome/",date,"_Core-microbiome_V1_",rank,"-level_",classifyr,"_",setting,".pdf"), width = 20, height = 20, units = "cm")
    ggsave(str_c(outfolder,"Core_microbiome/",date,"_Core-microbiome_V1_",rank,"-level_",classifyr,"_",setting,".png"), width = 20, height = 20, units = "cm")
    
  ggplot(core.microbiome,aes(x=reorder(Name, Percentage, FUN = median),y=Percentage)) +
      geom_violin(trim=FALSE, fill="gray")+
      #geom_boxplot(color = "black", show.legend = FALSE, width=0.1) +
    #geom_jitter(position=position_jitter(0.01)) +
    #geom_col(aes(y = 0.01, fill = Cluster), width = 0.9) + 
    facet_grid(cols = vars(Time),rows = vars(Cluster), scales = "free_y",space = "free_y")+ 
    #coord_trans(y="log10")+
    #scale_colour_grey(start=0.8, end=0.2)+
    #scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    #scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    #geom_hline(yintercept=10, linetype="dashed", color = "black")+
    scale_y_continuous(limits = c(0.01,100),name ="Percentage", trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
    geom_hline(yintercept=0.1, linetype="dashed", color = "black")+
    #annotation_logticks(sides = "l")+
    coord_flip()+
    theme_bw()+
    theme(panel.grid.minor = element_blank())+
    xlab("")
  
  # p2<-ggplot(core.microbiome, aes(x=reorder(Name, Percentage, FUN = median), y=0.5, fill=Cluster)) +
  #   geom_tile(color="white", size=0.1) +
  #   facet_grid(rows = vars(Cluster), scales = "free_y",space = "free_y")+ #cols = vars(Time),
  #   scale_fill_manual(values = c("C1" = "#bdbdbd", "C2" = "#969696", "C3" = "#737373", "C4" = "#525252"))+
  #   coord_flip()+
  #   labs(x=NULL, y=NULL, title=NULL)+
  #   theme_minimal()+
  #   ylab("Cluster")
  
  # # combine both plots 
  # ggarrange(p1, p2, labels = c("a", "b"), ncol = 2, nrow = 1, align = "h", widths = c(2, 1), common.legend = TRUE, legend = "right")
  
    # save plots
    ggsave(str_c(outfolder,"Core_microbiome/",date,"_Core-microbiome_V2_",rank,"-level_",classifyr,"_",setting,".pdf"), width = 24, height = 25, units = "cm")
    ggsave(str_c(outfolder,"Core_microbiome/",date,"_Core-microbiome_V2_",rank,"-level_",classifyr,"_",setting,".png"), width = 24, height = 25, units = "cm")
  }
}
```



# Part 3: Longitudinal and temporal analysis (rare taxa analysis)
### PCA analysis on the downsampled date
```{python, eval=FALSE}
use_condaenv("PuntSeq-analysis-env")

import os
import pandas as pd 
import numpy as np
import datetime
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
import matplotlib.transforms as transforms
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

DATE = datetime.datetime.now().strftime('%Y-%m-%d')
outfolder = DATE + '_PuntSeq_Metagenomics-analysis/'
os.mkdir(outfolder+'PCA/')

def confidence_ellipse(x, y, ax, n_std=2.0, facecolor='none', alpha=0.5, **kwargs):
    """
    Create a plot of the covariance confidence ellipse of `x` and `y`

    Parameters
    ----------
    x, y : array_like, shape (n, )
        Input data.

    ax : matplotlib.axes.Axes
        The axes object to draw the ellipse into.

    n_std : float
        The number of standard deviations to determine the ellipse's radiuses.

    Returns
    -------
    matplotlib.patches.Ellipse

    Other parameters
    ----------------
    kwargs : `~matplotlib.patches.Patch` properties
    """
    if x.size != y.size:
        raise ValueError("x and y must be the same size")

    cov = np.cov(x, y)
    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])
    # Using a special case to obtain the eigenvalues of this
    # two-dimensionl dataset.
    ell_radius_x = np.sqrt(1 + pearson)
    ell_radius_y = np.sqrt(1 - pearson)
    ellipse = Ellipse((0, 0),
        width=ell_radius_x * 2,
        height=ell_radius_y * 2,
        facecolor=facecolor, alpha=alpha, linestyle='None', edgecolor=facecolor,
        **kwargs)

    # Calculating the stdandard deviation of x from
    # the squareroot of the variance and multiplying
    # with the given number of standard deviations.
    scale_x = np.sqrt(cov[0, 0]) * n_std
    mean_x = np.mean(x)

    # calculating the stdandard deviation of y ...
    scale_y = np.sqrt(cov[1, 1]) * n_std
    mean_y = np.mean(y)

    transf = transforms.Affine2D() \
        .rotate_deg(45) \
        .scale(scale_x, scale_y) \
        .translate(mean_x, mean_y)

    ellipse.set_transform(transf + ax.transData)
    return ax.add_patch(ellipse)
    

def autolabel_feat(rects, R_df, ax):
    """
    Attach a text label above each bar displaying its height
    """
    m = 0
    for rect in rects:
        width = rect.get_width()
        if width != 0:
            ax.text(0.01, rect.get_y() + rect.get_height()/10. ,'%s' % R_df.index[m], ha='left', va='bottom')

        m += 1

def autolabel2_feat(rects, R_df, ax):
    """
    Attach a text label above each bar displaying its height
    """
    m = 0
    for rect in rects:
        width = rect.get_width()
        if width != 0:
            ax.text(-0.01, rect.get_y() + rect.get_height()/10. ,'%s' % R_df.index[m], ha='right', va='bottom')

        m += 1
        
        

### load one downsampled dataset and prepare PCA
nr = 1 
data = pd.read_csv(outfolder+'Downsampling/genus/final_%s.tsv' %nr, sep='\t', index_col=0, header=0)

# plot PCA of all remaining samples (>30k reads)
x = data.copy()

# save positive controls in different dataframes to plot them on top of the PCA later
x2 = x[['Mock-April_genus.tsv','Mock-June_genus.tsv','Mock-August_genus.tsv']]

# delte positive and negative controls
del x['N-August_genus.tsv']
del x['Mock-April_genus.tsv']; del x['Mock-August_genus.tsv']; del x['Mock-June_genus.tsv']

datacolumns = x.columns

# transpose to have the features in the column of the dataframe
x = x.transpose()
x2 = x2.transpose()

# logarithmise and standardise the features by removing the mean and scaling to unit variance
x = np.log10(x + 1)
x = StandardScaler().fit_transform(x)

x2 = np.log10(x2 + 1)
x2 = StandardScaler().fit_transform(x2)

# define a PCA with 10 components and 
pca = PCA(n_components=10)

# fit the PCA based on all water samples ('x'), the only transform the positive controls ('x2')
principalComponents = pca.fit_transform(x)
principalComponents2 = pca.transform(x2)
principalDf = pd.DataFrame(data = principalComponents, columns = ['PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6', 'PC 7', 'PC 8', 'PC 9', 'PC 10'])

# define target (location) and time point (month) per sample
principalDf['target'] = datacolumns
principalDf['month'] = [x.split('-')[1].split('_')[0] for x in principalDf.target.values]

# transform data
principalDf.index = principalDf.month
principalDf['targetnice'] = [x.split('-')[0] for x in principalDf.target.values]
b, c = principalDf.iloc[1], principalDf.iloc[2]
temp = principalDf.iloc[1].copy()
principalDf.iloc[1] = c
principalDf.iloc[2] = temp

principalComponents2 = pd.DataFrame(data = principalComponents2, columns = ['PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6', 'PC 7', 'PC 8', 'PC 9', 'PC 10'])
principalComponents2['target'] = ['Mock-April_genus.tsv','Mock-June_genus.tsv','Mock-August_genus.tsv']
principalComponents2['month'] = ['April','June','August']
principalComponents2['targetnice'] = ['P','P','P']
principalComponents2.index = ['April','June','August']
principalDf = pd.concat([principalDf, principalComponents2])


### plot PCA 

plt.style.use('classic')

# choose PCs
pc1 = 1
pc2 = 2

# plot and add percentage variance explained to the axes
n1 = 'PC %i' %pc1
n2 = 'PC %i' %pc2
var1 = pca.explained_variance_ratio_[pc1-1]
var2 = pca.explained_variance_ratio_[pc2-1]

fig, ax = plt.subplots(figsize=(8, 6), facecolor='white')
ax.set_xlabel('%s (Variance = %s)' % (n1,'%.3f'%(var1)), fontsize = 12)
ax.set_ylabel('%s (Variance = %s)'% (n2, '%.3f'%(var2)), fontsize = 12)

for target, color in zip(['April','June','August'], ['#66c2a5','#fc8d62', '#8da0cb']):
    indicesToKeep = principalDf['month'] == target
    ellip = np.array(principalDf.loc[indicesToKeep, [n1,n2]])
    ell = confidence_ellipse(ellip[:,0], ellip[:,1], ax=ax, facecolor=color, alpha=0.3)
    plt.scatter(np.mean(ellip[:,0]), np.mean(ellip[:,1]), facecolor=color, s=10)
    ax.scatter(principalDf.loc[indicesToKeep, n1]
               , principalDf.loc[indicesToKeep, n2]
               , c = color
               , s = 50
               , edgecolors='none')
    
for label, x, y in zip(principalDf.targetnice.values, principalDf[n1].values, principalDf[n2].values):
    plt.annotate(
        label,
        xy=(x, y), xytext=(-6, -8),
        textcoords='offset points', ha='right', va='bottom',
        fontsize=10)  

ax.legend(('April', 'June', 'August'), scatterpoints=1, markerscale=1.2,borderpad=0.5,labelspacing=1,loc=1,fontsize=12, ncol=1,fancybox=True,shadow=False,frameon=False,numpoints=1)
plt.axhline(0, c='black')
plt.axvline(0, c='black')
ax.set_axis_bgcolor('white')
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.yaxis.set_ticks_position('left')
ax.xaxis.set_ticks_position('bottom')


fig.savefig(outfolder+'PCA/PCA_%i_%i.pdf' %(pc1,pc2), bbox_inches='tight')


### examine the contributions of bacteria to the PCs
# choose PCs
pc1 = 1
pc2 = 2
n1 = 'PC %i' %pc1
n2 = 'PC %i' %pc2

datap = pd.DataFrame(pca.components_[[pc1-1,pc2-1],], index = [n1,n2], columns = data.index)
datap = datap.transpose()

# sort according to one PC
pc_c = n1
dataps = datap.copy()  
dataps['PCabs'] = dataps[pc_c].abs()         
dataps = dataps.sort('PCabs', ascending=False)    
# look at top 10 contributing bacteria
dataps[pc_c].head(n=10)      

# plot contributions as a barplot
n_bacteria = 10
dataplot = dataps[pc_c].head(n=n_bacteria)   

negative_data = []
positive_data = []
negative_data_std = []
positive_data_std = []
for feature in dataplot.index:
    if dataplot.loc[feature] >= 0:
        positive_data.append(dataplot.loc[feature])
        negative_data.append(0)
    elif dataplot.loc[feature] < 0:
        negative_data.append(dataplot.loc[feature])
        positive_data.append(0)
        
x = range(n_bacteria)[::-1]
fig = plt.figure(figsize=(6, 10), facecolor='white')
ax = plt.subplot(111)
rects1= ax.barh(x, negative_data, align='edge', color='sienna', ecolor='black', alpha=0.7, capsize=4) 
rects2 = ax.barh(x, positive_data, align='edge', color='cornflowerblue', ecolor='black',alpha=0.7, capsize=4) 
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.set_visible(False)
plt.axvline(x=0., color="black")
ax.yaxis.set_ticks_position('left')
ax.xaxis.set_ticks_position('bottom')


autolabel_feat(rects1, dataplot[:n], ax)
autolabel2_feat(rects2, dataplot[:n], ax)
    
ax.set_xlabel('contribution to %s' %pc_c)
fig.savefig(outfolder+'PCA/PCA_contributions_%s.pdf' %pc_c, bbox_inches='tight')





### apply PCA to ionics data (also available on github)
url = "https://raw.githubusercontent.com/d-j-k/puntseq/master/Ionics_Table.xlsx"
s = requests.get(url).content
data = pd.read_excel(io.StringIO(s.decode('utf-8')), 'Environmental metadata (sample)')

# clean up dataframe
data.columns = data.iloc[1,:]
data.columns.values[5:] = data.iloc[2,5:]
data = data.drop([0,1,2])
data['month'] = 'April'
data['month'][data.Batch==2] = 'June'
data['month'][data.Batch==3] = 'August'
data['targetnice'] = data.Barcode
targetnice = data.targetnice.values
month = data.month.values
# only save ionics in actual dataframe, delete all metadata
data = data.iloc[:,4:]
x = data.iloc[:,:-2]

# delete Fe, Mn and Al (can't be trusted)
del x['Fe']; del x['Mn']; del x['Al']

datacolumns = x.columns 

# logarithmise and standardise dataframe
x = x.astype(np.float64)
x = np.log10(x + 1)
x = StandardScaler().fit_transform(x)

# initiate PCA with 10 PCs
pca = PCA(n_components=10)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents, columns = ['PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6', 'PC 7', 'PC 8', 'PC 9', 'PC 10'])
principalDf['targetnice'] = targetnice
principalDf['month'] = month
principalDf.index = principalDf.month

# choose PCs
pc1 = 1
pc2 = 2
n1 = 'PC 1'
n2 = 'PC 2'
var1 = pca.explained_variance_ratio_[pc1-1]
var2 = pca.explained_variance_ratio_[pc2-1]

fig, ax = plt.subplots(figsize=(8, 6), facecolor='white')
ax.set_xlabel('%s (Variance = %s)' % (n1,'%.3f'%(var1)), fontsize = 12)
ax.set_ylabel('%s (Variance = %s)'% (n2, '%.3f'%(var2)), fontsize = 12)

for target, color in zip(['April','June','August'], ['#66c2a5','#fc8d62', '#8da0cb']):
    indicesToKeep = principalDf['month'] == target
    ellip = np.array(principalDf.loc[indicesToKeep, [n1,n2]])
    confidence_ellipse(ellip[:,0], ellip[:,1], ax=ax, facecolor=color, alpha=0.3)
    ax.scatter(principalDf.loc[indicesToKeep, n1]
               , principalDf.loc[indicesToKeep, n2]
               , c = color
               , s = 50
               , edgecolors='none')

for label, x, y in zip(principalDf.targetnice.values, principalDf[n1].values, principalDf[n2].values):
    plt.annotate(
        label,
        xy=(x, y), xytext=(-6, -8),
        textcoords='offset points', ha='right', va='bottom',
        fontsize=10)  
    
ax.legend(('April', 'June', 'August'), scatterpoints=1, markerscale=1.2,borderpad=0.5,labelspacing=1,loc=2,fontsize=12, ncol=1,fancybox=True,shadow=False,frameon=False,numpoints=1)
plt.axhline(0, c='black')
plt.axvline(0, c='black')
ax.set_axis_bgcolor('white')
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.yaxis.set_ticks_position('left')
ax.xaxis.set_ticks_position('bottom')

fig.savefig(outfolder+'PCA/PCA_ionics_%i_%i.pdf' %(pc1,pc2), bbox_inches='tight')



### asssess contributions to PCs 
# choose PCs
pc1 = 1
pc2 = 2
n1 = 'PC 1'
n2 = 'PC 2'
datap = pd.DataFrame(pca.components_[[pc1-1,pc2-1],], index = [n1,n1], columns = datacolumns)
datap = datap.transpose()
n = datap.shape[0]       

# show contributions of all ionics to chosen PC
pc_c = n1
dataps = datap.copy()  
dataps['PCabs'] = dataps[pc_c].abs()         
dataps = dataps.sort('PCabs', ascending=False)    
dataps[pc_c].head(n=n)      

dataion = dataps[pc_c].head(n=n)     

# transform features and plot barplot of contributions
negative_data = []
positive_data = []
negative_data_std = []
positive_data_std = []
for feature in dataion.index:
    if dataion.loc[feature] >= 0:
        positive_data.append(dataion.loc[feature])
        negative_data.append(0)
    elif dataion.loc[feature] < 0:
        negative_data.append(dataion.loc[feature])
        positive_data.append(0)

x = range(n)[::-1]

fig = plt.figure(figsize=(6, 10), facecolor='white')
ax = plt.subplot(111)
rects1 = ax.barh(x, negative_data, align='edge', color='sienna', ecolor='black', alpha=0.7, capsize=4) 
rects2 = ax.barh(x, positive_data, align='edge', color='cornflowerblue', ecolor='black',alpha=0.7, capsize=4) 
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.set_visible(False)
plt.axvline(x=0., color="black")
ax.yaxis.set_ticks_position('left')
ax.xaxis.set_ticks_position('bottom')

autolabel_feat(rects1, dataion[:n], ax)
autolabel2_feat(rects2, dataion[:n], ax)
    
ax.set_xlabel('contribution to %s' %pc_c)
fig.savefig(outfolder+'PCA/PCA_ionics_contributions_%s.pdf' %pc_c, bbox_inches='tight')

```

# Part 4: Environmental and interesting genera
### Pathogenic families/genera
```{r eval=FALSE}
# on family level
Pathogens_list_family_raw <- read_tsv("./Data/2019-06-16_Pathogens_List_family.txt")
Pathogens_list_family_selection <- Pathogens_list_family_raw

Pathogens_list_family_selection$max <- apply(Pathogens_list_family_raw[, 2:17], 1, max)

for (i in c(1:nrow(Pathogens_list_family_selection))){
  if(Pathogens_list_family_selection[i,21] < 10) {
    for (j in c(2:17)){
      Pathogens_list_family_selection[i,j] = 0
    }
  }  
}

Pathogens_list_family_toscale <- Pathogens_list_family_selection[1:17]
scaled_rows = t( scale(t(Pathogens_list_family_toscale[2:17] )))

# check that we get mean of 0 and sd of 1
rowMeans(scaled_rows)  # faster version of apply(scaled.dat, 2, mean)
apply(scaled_rows, 1, sd)

Pathogens_list_family_scaled<- bind_cols(Pathogens_list_family_toscale[1], data.frame(scaled_rows))

Pathogens_list_family_normalised <- gather(Pathogens_list_family_scaled, key = "Location", value = "Reads_normalised", 2:17) %>%
  mutate(Location = str_replace(Location, pattern = "X", "")) %>%
  mutate(Location = str_replace(Location, pattern = "\\.\\.\\.", " - "))
  
Pathogens_list_family <- gather(Pathogens_list_family_raw, key = "Location", value = "Reads", 2:20) %>% 
  filter(Location != "P - April" & Location != "P - June" & Location != "P - August") #%>%
  #filter(Family != "Burkholderiaceae") %>%
  #mutate(row = group_indices_(Pathogens_list_family, .dots=c('Family', 'Location'))) 
Pathogens_list_family$log <- log2(Pathogens_list_family$Reads+1)
# get character vector of variable names for the x axis. the order is important, hence arrange(col)!
#vars_x_axis <- c(df %>% arrange(Location) %>% select(variable) %>% distinct())$variable
# get character vector of observation names for the y axis. again, the order is important but "df" is already ordered
#names_y_axis <- c(df %>% group_by(row) %>% distinct(name) %>% ungroup() %>% select(name))$name

Pathogens_list_family_all <- right_join(Pathogens_list_family, Pathogens_list_family_normalised )

# boxplot
ggplot(Pathogens_list_family, aes(Family, Reads+1)) +
  #geom_jitter(aes(colour = Location),show.legend = FALSE)+
  geom_boxplot(color = "black",fill="grey",show.legend = FALSE) +
  scale_y_continuous(name ="Reads",trans=log10_trans(), breaks=c(10, 100, 1000, 10000), label = comma)+
  coord_trans(y="log10")+
  #scale_colour_grey(start=0.8, end=0.2)+
  #scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
  #scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
  geom_hline(yintercept=10, linetype="dashed", color = "black")+
  coord_flip()+
  theme_minimal()+
  theme(axis.ticks = element_blank())+
  xlab("")

ggsave(str_c("./Plots/",date,"Pathogens_family-level_bubble-chart_1.pdf"), width = 10, height = 20, units = "cm")
ggsave(str_c("./Plots/",date,"Pathogens_family-level_bubble-chart_1.png"), width = 10, height = 20, units = "cm")

#normalised dispersion from mean SD
ggplot(Pathogens_list_family_normalised, aes(x=factor(Location), y=factor(Family), size=abs(Reads_normalised), fill=Reads_normalised)) +
  geom_point(shape = 21,alpha=1, colour="grey") +    # plot as points
  #geom_text(aes(), alpha=1.0, size=3) +   # display the value next to the "balloons"
  #scale_alpha_continuous(range=c(0.2, 0.8)) +
  #scale_size_area(range = c(0, 4)) +
  scale_size(range = c(0.1, 7.5),name = "")+
  #scale_x_discrete(breaks=1:length(vars_x_axis), labels=vars_x_axis, position='top') +   # set the labels on the X axis
  #scale_y_discrete(breaks=1:length(names_y_axis), labels=names_y_axis) +                 # set the labels on the Y axis+
  scale_fill_gradient2(name = "")+
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, hjust = 1),
        axis.text.y = element_blank(),
        axis.line = element_blank(),            # disable axis lines
        axis.ticks = element_blank(),
        axis.title = element_blank(),           # disable axis titles
        panel.border = element_blank(),         # disable panel border
        panel.grid.major.x = element_blank(),   # disable lines in grid on X-axis
        panel.grid.minor.x = element_blank())   # disable lines in grid on X-axis

ggsave(str_c("./Plots/",date,"Pathogens_family-level_bubble-chart_2.pdf"), width = 15, height = 20, units = "cm")
ggsave(str_c("./Plots/",date,"Pathogens_family-level_bubble-chart_2.png"), width = 15, height = 20, units = "cm")


#####

# on genus level
Pathogens_list_genus_raw <- read_tsv("./Data/2019-06-16_Pathogens_List_genus.txt")
Pathogens_list_genus_selection <- Pathogens_list_genus_raw

Pathogens_list_genus_selection$max <- apply(Pathogens_list_genus_raw[, 3:18], 1, max)

for (i in c(1:nrow(Pathogens_list_genus_selection))){
  if(Pathogens_list_genus_selection[i,22] < 10) {
    for (j in c(3:18)){
      Pathogens_list_genus_selection[i,j] = 0
    }
  }  
}

Pathogens_list_genus_toscale <- Pathogens_list_genus_selection[1:18]
scaled_rows = t( scale(t(Pathogens_list_genus_toscale[3:18] )))

# check that we get mean of 0 and sd of 1
rowMeans(scaled_rows)  # faster version of apply(scaled.dat, 2, mean)
apply(scaled_rows, 1, sd)

Pathogens_list_genus_scaled<- bind_cols(Pathogens_list_genus_toscale[1:2], data.frame(scaled_rows))

Pathogens_list_genus_normalised <- gather(Pathogens_list_genus_scaled, key = "Location", value = "Reads_normalised", 3:18) %>%
  mutate(Location = str_replace(Location, pattern = "X", "")) %>%
  mutate(Location = str_replace(Location, pattern = "\\.\\.\\.", " - "))
  
Pathogens_list_genus <- gather(Pathogens_list_genus_raw, key = "Location", value = "Reads", 3:21) %>% 
  filter(Location != "P - April" & Location != "P - June" & Location != "P - August") #%>%
  #filter(genus != "Burkholderiaceae") %>%
  #mutate(row = group_indices_(Pathogens_list_genus, .dots=c('genus', 'Location'))) 
Pathogens_list_genus$log <- log2(Pathogens_list_genus$Reads+1)
# get character vector of variable names for the x axis. the order is important, hence arrange(col)!
#vars_x_axis <- c(df %>% arrange(Location) %>% select(variable) %>% distinct())$variable
# get character vector of observation names for the y axis. again, the order is important but "df" is already ordered
#names_y_axis <- c(df %>% group_by(row) %>% distinct(name) %>% ungroup() %>% select(name))$name

Pathogens_list_genus_all <- right_join(Pathogens_list_genus, Pathogens_list_genus_normalised )

# boxplot
ggplot(Pathogens_list_genus, aes(Genus, Reads+1)) +
  #geom_jitter(aes(colour = Location),show.legend = FALSE)+
  geom_boxplot(color = "black",fill="grey",show.legend = FALSE) +
  scale_y_continuous(name ="Reads",trans=log10_trans(), breaks=c(10, 100, 1000, 10000), label = comma)+
  coord_trans(y="log10")+
  #scale_colour_grey(start=0.8, end=0.2)+
  #scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
  #scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
  geom_hline(yintercept=10, linetype="dashed", color = "black")+
  coord_flip()+
  theme_minimal()+
  theme(axis.ticks = element_blank())+
  xlab("")

ggsave(str_c("./Plots/",date,"Pathogens_genus-level_bubble-chart_1.pdf"), width = 10, height = 20, units = "cm")
ggsave(str_c("./Plots/",date,"Pathogens_genus-level_bubble-chart_1.png"), width = 10, height = 20, units = "cm")

#normalised dispersion from mean SD
ggplot(Pathogens_list_genus_normalised, aes(x=factor(Location), y=factor(Genus), size=abs(Reads_normalised), fill=Reads_normalised)) +
  geom_point(shape = 21,alpha=1, colour="grey") +    # plot as points
  #geom_text(aes(), alpha=1.0, size=3) +   # display the value next to the "balloons"
  #scale_alpha_continuous(range=c(0.2, 0.8)) +
  #scale_size_area(range = c(0, 4)) +
  scale_size(range = c(0.1, 7.5),name = "")+
  #scale_x_discrete(breaks=1:length(vars_x_axis), labels=vars_x_axis, position='top') +   # set the labels on the X axis
  #scale_y_discrete(breaks=1:length(names_y_axis), labels=names_y_axis) +                 # set the labels on the Y axis+
  scale_fill_gradient2(name = "")+
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, hjust = 1),
        axis.text.y = element_blank(),
        axis.line = element_blank(),            # disable axis lines
        axis.ticks = element_blank(),
        axis.title = element_blank(),           # disable axis titles
        panel.border = element_blank(),         # disable panel border
        panel.grid.major.x = element_blank(),   # disable lines in grid on X-axis
        panel.grid.minor.x = element_blank())   # disable lines in grid on X-axis

ggsave(str_c("./Plots/",date,"Pathogens_genus-level_bubble-chart_2.pdf"), width = 15, height = 20, units = "cm")
ggsave(str_c("./Plots/",date,"Pathogens_genus-level_bubble-chart_2.png"), width = 15, height = 20, units = "cm")
```

## tests
```{r}
set<-1
# Prepare data for annotation 
  selection <- filter(clean_classified_reads_downsampled[[set]], TaxRank == "G", Percentage != "NA", Location != "N" & Location != "Mock") %>%
    unite("ID", c("Location","Time"), sep = " - ") %>%
    filter(Name == "Dechloromonas")
  

ggplot(data = selection, mapping = aes(x = ID, y = Percentage))+
  geom_bar(stat="identity",position = position_dodge(), width = 0.7)#+
  facet_grid(cols = vars(Location))+ 
  geom_hline(yintercept=30000, linetype="dashed", color = "black")+
  labs(title = "Level of Classifiation",y = "Reads (1)")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 22))+
  theme(axis.text.x = element_text(size = 16))+
  theme(axis.text.y = element_text(size = 14))+
  theme(legend.text = element_text(size = 16))+
  theme(legend.title = element_blank())+
  #scale_fill_grey()+
  scale_fill_manual(values=c("#636363","#bdbdbd","#d9d9d9","#56B4E9","#ccebc5")
                    
```



# Part 5: Additional analyses
### Correlation analysis classifier
```{r eval=FALSE}
# # Load data into dataframe
# correlation.data.raw <- read_tsv("summary_pos_cor.tsv")
# correlation.data <- correlation.data.raw %>%
#   gather(key = "Set", value = "Observed_composition", 4:51) %>%
#   mutate(Observed_composition = Observed_composition *100) %>%
#   separate(Set, into = c("Basecaller","Classifier","Time"), sep="_") %>%
#   separate(Classifier, into = c("Classifier","Database"), sep="16") %>%
#   mutate(Database = ifelse(grepl("S", Database), "SILVA", "NCBI")) %>%
#   mutate(Classifier = str_replace(Classifier, pattern = "bracken", "Bracken")) %>%
#   mutate(Classifier = str_replace(Classifier, pattern = "kraken", "Kraken")) %>%
#   mutate(Classifier = str_replace(Classifier, pattern = "centrifuge", "Centrifuge")) %>%
#   unite("ID", c("Classifier","Database"), sep = " ") %>%
#   filter(X1 != "R" & X1 != "P")
# 
# # Correlation between DNA yield and PCR yield
# ggscatter(correlation.data , x = "Expected_composition", y = "Observed_composition",
#           add = "reg.line",                         # Add regression line: loss = local regression fitting; reg.line = liniear regression         
#           # conf.int = TRUE,                        # Add confidence interval
#           color = "Time", palette = "grey",size = 2,          # Color by groups "cyl"
#           # shape = "Experiment",                             # Change point shape by groups "cyl"
#           facet.by = c("Basecaller","ID"),
#           # yscale = "log10",
#           # add.params = list(color = "blue", fill = "lightgray"), # Customize reg. line
#           xticks.by = 10,
#           yticks.by = 10,
#           xlim = c(0, 60),
#           ylim = c(0, 60)
#           )+
#   labs(title = "", caption = waiver(), x="expected ratio of taxa [%]", y="observed ratio of taxa [%]")+
#   theme(legend.position="right")+
#   stat_cor(label.x = 2,label.y = 45, size = 4, method = "pearson", col="black")           # Add correlation coefficient
# 
# ggsave(str_c(outfolder,"Overview-plots/",date,"_Correlation_plots.png"), width = 40, height = 15, units = "cm")
# ggsave(str_c(outfolder,"Overview-plots/",date,"_Correlation_plots.pdf"), width = 40, height = 15, units = "cm") 
# 
#   # geom_point(aes(color=Time))+
#   # scale_color_grey()+
#   # 
#   # geom_smooth(se = TRUE, method = "lm", formula = y ~ x, color = "black")+
#   # 
#   # 

```

### (Please check warnings) Correlation analysis classifier (genus level; 'Loman' equals the shotgun mock community as described in the manuscript)
```{python, eval=FALSE}
<!-- import os -->
<!-- import pandas as pd  -->
<!-- import numpy as np -->
<!-- import datetime -->
<!-- import matplotlib.pyplot as plt -->
<!-- from sklearn.linear_model import LinearRegression -->
<!-- import requests -->
<!-- import io -->
<!-- import scipy -->
<!-- import pylab -->

<!-- DATE = datetime.datetime.now().strftime('%Y-%m-%d') -->
<!-- outfolder = DATE + '_PuntSeq_Metagenomics-analysis/' -->
<!-- os.mkdir(outfolder+'positive_control/') -->

<!-- for basecaller in ['Albacore','Guppy']: -->
<!--     for classi in ['kraken16S','centrifuge', 'centrifuge16S', 'kraken', 'bracken', 'kraken16S', 'bracken16S']: -->
<!--         for month in ['April','June', 'August', 'Loman']: -->
<!--             if classi == 'kraken16S': -->
<!--                 classi2 = 'Kraken2 SILVA' -->
<!--             if classi == 'kraken': -->
<!--                 classi2 = 'Kraken2 NCBI' -->
<!--             if classi == 'bracken16S': -->
<!--                 classi2 = 'Bracken SILVA' -->
<!--             if classi == 'bracken': -->
<!--                 classi2 = 'Bracken NCBI' -->
<!--             if classi == 'centrifuge16S': -->
<!--                 classi2 = 'Cenrifuge SILVA' -->
<!--             if classi == 'centrifuge': -->
<!--                 classi2 = 'Cenrifuge NCBI' -->

<!--             taxrank = 'G' # 'U', '-', 'D', 'P', 'C', 'O', 'F', 'G', 'S' -->
<!--             taxrank2 = 'genus' -->

<!--             url = "https://raw.githubusercontent.com/d-j-k/puntseq/master/analysis/data/Analysis_bioRxiv/"+basecaller+"/"+month+"_"+classi+".tsv" -->
<!--             s = requests.get(url).content -->
<!--             april = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='\t', index_col=0, header=0) -->

<!--             if month == 'Loman': -->
<!--                 new = april.columns.values -->
<!--                 new[3] = 'BC08_abs' -->
<!--                 april.columns = new -->
<!--             else:  -->
<!--                 april.columns = [x.split('.')[0] for x in april.columns] -->
<!--                 april.columns = [x.split('_')[-1] for x in april.columns] -->
<!--                 april.columns.values[3:15] = [x + '_abs' for x in april.columns[3:15]] -->

<!--             # get one taxonomic level:  -->
<!--             aprilg = april[april.taxRank==taxrank] -->

<!--             ### choose positive control -->
<!--             aprilg8 = aprilg['BC08_abs'] -->

<!--             genera = np.array(['Pseudomonas', 'Escherichia', 'Salmonella', 'Lactobacillus', 'Enterococcus', 'Staphylococcus', 'Listeria', 'Bacillus']) -->
<!--             if classi[-3:] == '16S': -->
<!--                 genera = np.array(['Pseudomonas', 'Escherichia-Shigella', 'Salmonella', 'Lactobacillus', 'Enterococcus', 'Staphylococcus', 'Listeria', 'Bacillus']) -->
<!--             ## if family or order: -->
<!--             #genera = np.array(['Pseudomonadaceae', 'Enterobacteriaceae', 'Lactobacillaceae', 'Enterococcaceae', 'Staphylococcaceae', 'Listeriaceae', 'Bacillaceae']) -->
<!--             #genera = np.array(['Pseudomonadales', 'Enterobacterales', 'Lactobacillales', 'Bacillales']) -->
<!--             #if classi[-3:] == '16S': -->
<!--                 #genera = np.array(['Pseudomonadales', 'Enterobacteriales', 'Lactobacillales', 'Bacillales']) -->

<!--             # allocate expected 16S ratio (from Zymobiomics protocol) -->
<!--             generaexp = np.array([4.2, 10.1, 10.4, 18.4, 9.9, 15.5, 14.1, 17.4]) -->
<!--             ## if family or order: -->
<!--             #generaexp = np.array([4.2, 10.1+10.4, 18.4, 9.9, 15.5, 14.1, 17.4]) -->
<!--             #generaexp = np.array([4.2, 10.1+10.4, 18.4+9.9, 15.5+14.1+17.4]) -->

<!--             # allocate expected shotgun ratio (from Zymobiomics protocol) -->
<!--             if month == 'Loman': -->
<!--                 generaexp = np.array([6.1, 8.5, 8.7, 21.6, 14.6, 15.2, 13.9, 10.3]) -->
<!--                 ## if family or order: -->
<!--                 #generaexp = np.array([6.1, 8.5+8.7, 21.6, 14.6, 15.2, 13.9, 10.3]) -->
<!--                 #generaexp = np.array([6.1, 8.5+8.7, 21.6+14.6, 15.2+13.9+10.3]) -->


<!--             generaabs = aprilg8.loc[genera].values/aprilg8.sum() -->
<!--             generaabs[np.isnan(generaabs)] = 0 -->

<!--             # values without Ecoli (to calculate correlations) [nr might chance on different taxonomic level] -->
<!--             generae = np.delete(genera, 1) -->
<!--             generaexpe = np.delete(generaexp, 1) -->
<!--             generaabse = np.delete(generaabs, 1) -->

<!--             # assign values per month -->
<!--             if month == 'April': -->
<!--                 gaA = generaabs.copy() -->
<!--                 geA = generaexp.copy() -->
<!--                 gaAe = generaabse.copy() -->
<!--                 geAe = generaexpe.copy() -->
<!--             if month == 'June': -->
<!--                 gaJ = generaabs.copy() -->
<!--                 geJ = generaexp.copy() -->
<!--                 gaJe = generaabse.copy() -->
<!--                 geJe = generaexpe.copy() -->
<!--             if month == 'August': -->
<!--                 gaAU = generaabs.copy() -->
<!--                 geAU = generaexp.copy() -->
<!--                 gaAUe = generaabse.copy() -->
<!--                 geAUe = generaexpe.copy() -->
<!--             if month == 'Loman': -->
<!--                 gaL = generaabs.copy() -->
<!--                 geL = generaexp.copy() -->
<!--                 gaLe = generaabse.copy() -->
<!--                 geLe = generaexpe.copy() -->



<!--         # plot -->
<!--         plt.style.use('classic') -->


<!--         fig, ax = plt.subplots(figsize=(8, 8), facecolor='white') -->

<!--         maxaxis = 70 -->
<!--         plt.xlim(-1, maxaxis) -->
<!--         plt.ylim(-1, maxaxis) -->


<!--         # linear regression without E.coli -->
<!--         modele = LinearRegression(fit_intercept=True) -->
<!--         modele.fit(geAe.reshape(-1, 1), (gaAe * 100).reshape(-1, 1)) -->
<!--         xfiteA = np.linspace(0, maxaxis, 100) -->
<!--         yfiteA = modele.predict(xfiteA.reshape(-1, 1)) -->
<!--         plt.plot(xfiteA, yfiteA, 'g', label = 'April R = %.3f'%(scipy.stats.pearsonr(geAe, gaAe * 100)[0]),  -->
<!--                  linestyle='dashed', color='0') -->
<!--         ax.scatter(geA, gaA * 100, color='0', label='', edgecolor='none', s=200) -->

<!--         modele = LinearRegression(fit_intercept=True) -->
<!--         modele.fit(geJe.reshape(-1, 1), (gaJe * 100).reshape(-1, 1)) -->
<!--         xfiteJ = np.linspace(0, maxaxis, 100) -->
<!--         yfiteJ = modele.predict(xfiteJ.reshape(-1, 1)) -->
<!--         plt.plot(xfiteJ, yfiteJ, 'g', label = 'June R = %.3f'%(scipy.stats.pearsonr(geJe, gaJe * 100)[0]),  -->
<!--                  linestyle='dashed', color='0.3') -->
<!--         ax.scatter(geJ, gaJ * 100, color='0.3', label='', edgecolor='none', s=200) -->

<!--         modele = LinearRegression(fit_intercept=True) -->
<!--         modele.fit(geAUe.reshape(-1, 1), (gaAUe * 100).reshape(-1, 1)) -->
<!--         xfiteAU = np.linspace(0, maxaxis, 100) -->
<!--         yfiteAU = modele.predict(xfiteAU.reshape(-1, 1)) -->
<!--         plt.plot(xfiteAU, yfiteAU, 'g', label = 'August R = %.3f'%(scipy.stats.pearsonr(geAUe, gaAUe * 100)[0]),  -->
<!--                  linestyle='dashed', color='0.6') -->
<!--         ax.scatter(geAU, gaAU * 100, color='0.6', label='', edgecolor='none', s=200) -->

<!--         modele = LinearRegression(fit_intercept=True) -->
<!--         modele.fit(geLe.reshape(-1, 1), (gaLe * 100).reshape(-1, 1)) -->
<!--         xfiteL = np.linspace(0, maxaxis, 100) -->
<!--         yfiteL = modele.predict(xfiteL.reshape(-1, 1)) -->
<!--         plt.plot(xfiteL, yfiteL, 'g', label = 'Shotgun R = %.3f'%(scipy.stats.pearsonr(geLe, gaLe * 100)[0]),  -->
<!--                  linestyle='dashed', color='0.8') -->
<!--         ax.scatter(geL, gaL * 100, color='0.8', label='', edgecolor='none', s=200) -->

<!--         ax.get_xaxis().tick_bottom();ax.get_yaxis().tick_left() -->
<!--         ax.tick_params(labelsize=20) -->
<!--         pylab.xlabel('expected ratio of taxa [%]', fontsize=20); pylab.ylabel('observed ratio of taxa [%]', fontsize=20) -->
<!--         plt.title('%s %s' % (basecaller,classi2),fontsize=20) -->

<!--         plt.legend(prop = {'size':20},frameon=False,loc=1, fontsize=20) -->
<!--         plt.show() -->

<!--         fig.savefig(outfolder+'positive_control/Plot_%s_%s.pdf' %(basecaller,classi), bbox_inches='tight') -->

```



### Enterobacteriaceae abundance 
#### Downsampled data
```{r eval=FALSE}

classifyr <- "kraken16S downsampled"

subset_Ecoli <- filter(tidy_reads_kraken16S_downsampled, Name == "Enterobacteriaceae") %>%
  mutate(Time = str_replace(Time, pattern = "August", "Aug")) %>%
  transform( Time = factor(Time, levels = c("April","June","Aug")))

ggplot(data = subset_Ecoli, mapping = aes(x = Time, y = Reads))+
  geom_bar(stat="identity",position = position_dodge(), width = 0.7)+
  facet_grid(cols = vars(Location))+ 
  geom_hline(yintercept=30000, linetype="dashed", color = "black")+
  labs(title = "Level of Classifiation",y = "Reads (1)")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 22))+
  theme(axis.text.x = element_text(size = 16))+
  theme(axis.text.y = element_text(size = 14))+
  theme(legend.text = element_text(size = 16))+
  theme(legend.title = element_blank())+
  #scale_fill_grey()+
  scale_fill_manual(values=c("#636363","#bdbdbd","#d9d9d9","#56B4E9","#ccebc5"))+
  scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
  annotation_logticks(sides="l")

ggsave(str_c("./Plots/",date,"Enterobacteriaceae-in-downsampled_log_",classifyr,".png"), width = 60, height = 15, units = "cm")
ggsave(str_c("./Plots/",date,"Enterobacteriaceae-in-downsampled_log_",classifyr,".pdf"), width = 60, height = 15, units = "cm") 

ggplot(data = subset_Ecoli, mapping = aes(x = Time, y = Reads))+
  geom_bar(stat="identity",position = position_dodge(), width = 0.7)+
  facet_grid(cols = vars(Location))+ 
  geom_hline(yintercept=30000, linetype="dashed", color = "black")+
  labs(title = "Level of Classifiation",y = "Reads (1)")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 22))+
  theme(axis.text.x = element_text(size = 16))+
  theme(axis.text.y = element_text(size = 14))+
  theme(legend.text = element_text(size = 16))+
  theme(legend.title = element_blank())+
  #scale_fill_grey()+
  scale_fill_manual(values=c("#636363","#bdbdbd","#d9d9d9","#56B4E9","#ccebc5"))#+
  #scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
  #annotation_logticks(sides="l")

ggsave(str_c("./Plots/",date,"Enterobacteriaceae-in-downsampled_",classifyr,".png"), width = 60, height = 15, units = "cm")
ggsave(str_c("./Plots/",date,"Enterobacteriaceae-in-downsampled_",classifyr,".pdf"), width = 60, height = 15, units = "cm") 


ggplot(data = filter(subset_Ecoli, Location != "P"), mapping = aes(x = Time, y = Reads))+
  geom_bar(stat="identity",position = position_dodge(), width = 0.7)+
  facet_grid(cols = vars(Location))+ 
  #geom_hline(yintercept=30000, linetype="dashed", color = "black")+
  labs(title = "Level of Classifiation",y = "Reads (1)")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 22))+
  theme(axis.text.x = element_text(size = 16))+
  theme(axis.text.y = element_text(size = 14))+
  theme(legend.text = element_text(size = 16))+
  theme(legend.title = element_blank())+
  #scale_fill_grey()+
  scale_fill_manual(values=c("#636363","#bdbdbd","#d9d9d9","#56B4E9","#ccebc5"))#+
  #scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
  #annotation_logticks(sides="l")

ggsave(str_c("./Plots/",date,"Enterobacteriaceae-in-downsampled_withoutpositive",classifyr,".png"), width = 60, height = 15, units = "cm")
ggsave(str_c("./Plots/",date,"Enterobacteriaceae-in-downsampled_withoutpositive",classifyr,".pdf"), width = 60, height = 15, units = "cm") 

```

#### Full dataset
```{r eval=FALSE}

classifyr <- "kraken16S"

subset_Ecoli <- filter(clean_classified_reads, Name == "Enterobacteriaceae" | Name == "Escherichia-Shigella") %>%
  mutate(Time = str_replace(Time, pattern = "August", "Aug")) %>%
  transform( Time = factor(Time, levels = c("April","June","Aug")))

ggplot(data = subset_Ecoli, mapping = aes(x = Time, y = Reads, fill = Name))+
  geom_bar(stat="identity",position = position_dodge(), width = 0.7)+
  facet_grid(cols = vars(Location))+ 
  geom_hline(yintercept=30000, linetype="dashed", color = "black")+
  labs(title = "Level of Classifiation",y = "Reads (1)")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 22))+
  theme(axis.text.x = element_text(size = 16))+
  theme(axis.text.y = element_text(size = 14))+
  theme(legend.text = element_text(size = 16))+
  theme(legend.title = element_blank())+
  #scale_fill_grey()+
  scale_fill_manual(values=c("#636363","#56B4E9"))+
  scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
  annotation_logticks(sides="l")

ggsave(str_c("./Plots/",date,"Enterobacteriaceae-total_log_",classifyr,".png"), width = 60, height = 15, units = "cm")
ggsave(str_c("./Plots/",date,"Enterobacteriaceae-total_log_",classifyr,".pdf"), width = 60, height = 15, units = "cm") 


ggplot(data = filter(subset_Ecoli, Location != "P"), mapping = aes(x = Time, y = Reads, fill = Name))+
  geom_bar(stat="identity",position = position_dodge(), width = 0.7)+
  facet_grid(cols = vars(Location))+ 
  #geom_hline(yintercept=30000, linetype="dashed", color = "black")+
  labs(title = "Level of Classifiation",y = "Reads (1)")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 22))+
  theme(axis.text.x = element_text(size = 16))+
  theme(axis.text.y = element_text(size = 14))+
  theme(legend.text = element_text(size = 16))+
  theme(legend.title = element_blank())+
  #scale_fill_grey()+
  scale_fill_manual(values=c("#636363","#56B4E9"))#+
  #scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
  #annotation_logticks(sides="l")

ggsave(str_c("./Plots/",date,"Enterobacteriaceae-total_withoutpositive",classifyr,".png"), width = 60, height = 15, units = "cm")
ggsave(str_c("./Plots/",date,"Enterobacteriaceae-total_withoutpositive",classifyr,".pdf"), width = 60, height = 15, units = "cm") 


subset_Ecoli <- filter(clean_classified_reads, Name == "Enterobacteriaceae" | Name == "Escherichia-Shigella") %>%
  mutate(Time = str_replace(Time, pattern = "August", "Aug")) %>%
  transform( Time = factor(Time, levels = c("April","June","Aug")))

ggplot(data = subset_Ecoli, mapping = aes(x = Time, y = Percentage, fill = Name))+
  geom_bar(stat="identity",position = position_dodge(), width = 0.7)+
  facet_grid(cols = vars(Location))+ 
  #geom_hline(yintercept=30000, linetype="dashed", color = "black")+
  labs(title = "Level of Classifiation",y = "Percentage (%)")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 22))+
  theme(axis.text.x = element_text(size = 16))+
  theme(axis.text.y = element_text(size = 14))+
  theme(legend.text = element_text(size = 16))+
  theme(legend.title = element_blank())+
  #scale_fill_grey()+
  scale_fill_manual(values=c("#636363","#56B4E9"))#+
  #scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
  #annotation_logticks(sides="l")

ggsave(str_c("./Plots/",date,"Enterobacteriaceae-normalized",classifyr,".png"), width = 60, height = 15, units = "cm")
ggsave(str_c("./Plots/",date,"Enterobacteriaceae-normalized",classifyr,".pdf"), width = 60, height = 15, units = "cm") 

ggplot(data = filter(subset_Ecoli, Location != "P"), mapping = aes(x = Time, y = Reads, fill = Name))+
  geom_bar(stat="identity",position = position_dodge(), width = 0.7)+
  facet_grid(cols = vars(Location))+ 
  #geom_hline(yintercept=30000, linetype="dashed", color = "black")+
  labs(title = "Level of Classifiation",y = "Percentage (%)")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 22))+
  theme(axis.text.x = element_text(size = 16))+
  theme(axis.text.y = element_text(size = 14))+
  theme(legend.text = element_text(size = 16))+
  theme(legend.title = element_blank())+
  #scale_fill_grey()+
  scale_fill_manual(values=c("#636363","#56B4E9"))#+
  #scale_y_continuous(trans='log10', breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
  #annotation_logticks(sides="l")

ggsave(str_c("./Plots/",date,"Enterobacteriaceae-normalized_withoutpositive",classifyr,".png"), width = 60, height = 15, units = "cm")
ggsave(str_c("./Plots/",date,"Enterobacteriaceae-normalized_withoutpositive",classifyr,".pdf"), width = 60, height = 15, units = "cm") 

```


## Trash
```{r eval=FALSE}
# Distribution of classified vs. unclassified reads per location and time point on log10 scale
subset1_1<- filter(clean_classified_reads, Name == "root" | Name == "unclassified", Location != "N" & Location != "P") %>%
  mutate(Name = str_replace(Name, pattern = "root", "classified")) %>%
  transform( Name = factor(Name, levels = c("unclassified","classified")))

ggplot(data = subset1_1, mapping = aes(x = Location, y = Reads, fill = Name))+
  geom_bar(stat="identity", position="identity",width = 0.7)+
  facet_wrap(~Time)+
  geom_hline(aes(yintercept=30000, color = "Downsampling"), linetype="dashed")+
  labs(title = "Distribution of classified vs. unclassified reads per location and time point")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5, size = 11))+
  theme(axis.text.x = element_text(size = 7))+
  theme(axis.text.y = element_text(size = 7))+
  theme(legend.text = element_text(size = 8))+
  theme(legend.title = element_blank())+
  scale_fill_manual(values=c("#999999","#56B4E9"))+
  scale_y_continuous(labels = scientific_1, trans='log10')+
  coord_cartesian(ylim = c(10,10000000))

ggsave(str_c(outfolder,date,"_Distribution-of-classified-unclassified-reads-per-location-time-point_V3_",classifyr,".png"), width = 20, height = 15, units = "cm")
ggsave(str_c(outfolder,date,"_Distribution-of-classified-unclassified-reads-per-location-time-point_V3_",classifyr,".pdf"), width = 20, height = 15, units = "cm") 
```


```{r eval=FALSE}
# Prepare data for annotation 

selection <- filter(tidy_reads_kraken16S_downsampled, TaxRank == "F", Percentage != "NA", Location != "N" & Location != "P") %>%
  group_by(Name,Time) %>%
  summarize(Sum = sum(Reads, na.rm = TRUE)) %>%
  ungroup(Name,Time) %>%
  mutate(ring_level = ifelse(Time == "April", "1", Time)) %>%
  mutate(ring_level = ifelse(Time == "June", "2", ring_level)) %>%
  mutate(ring_level = ifelse(Time == "August", "3", ring_level)) %>%
  mutate(percentage = ifelse(Time == "April", Sum/(7*30000), 0)) %>%
  mutate(percentage = ifelse(Time == "June", Sum/(2*30000), percentage)) %>%
  mutate(percentage = ifelse(Time == "August", Sum/(7*30000), percentage)) %>%
  mutate(color = ifelse(Time == "April", "green", "black")) %>%
  mutate(color = ifelse(Time == "June", "red", color)) %>%
  mutate(color = ifelse(Time == "August", "blue", color)) %>%
  mutate(annotation = Name) %>%
  mutate(back_color = "k") %>%
  mutate(clade_color = "k") %>%
  mutate(clade_m_size = 40) %>%
  mutate(height = 1) %>%
  filter(percentage > 0.0075)
  
selection$ring_alpha <- "ring_alpha"
selection$ring_hight <- "ring_height"
selection$ring_color <- "ring_color"
selection$option_a <- "annotation" 
selection$option_abc <- "annotation_background_color" 
selection$option_cmc <- "clade_marker_color" 
selection$option_cms <- "clade_marker_size" 

write_tsv(select(selection, Name, ring_alpha, ring_level, percentage), "tmp_tree-annotation_2-0.txt", col_names = FALSE)
write_tsv(select(selection, Name, ring_hight, ring_level, height), "tmp_tree-annotation_2-1.txt", col_names = FALSE)
write_tsv(select(selection, Name, ring_color, ring_level, color), "tmp_tree-annotation_2-2.txt", col_names = FALSE)
write_tsv(select(selection, Name, option_a, annotation), "tmp_tree-annotation_2-3.txt", col_names = FALSE)
write_tsv(select(selection, Name, option_abc, back_color), "tmp_tree-annotation_2-4.txt", col_names = FALSE)
write_tsv(select(selection, Name, option_cmc, clade_color), "tmp_tree-annotation_2-5.txt", col_names = FALSE)
write_tsv(select(selection, Name, option_cms, clade_m_size), "tmp_tree-annotation_2-6.txt", col_names = FALSE)

system("cat tmp_tree-annotation_2-0.txt tmp_tree-annotation_2-1.txt tmp_tree-annotation_2-2.txt tmp_tree-annotation_2-3.txt tmp_tree-annotation_2-4.txt tmp_tree-annotation_2-5.txt tmp_tree-annotation_2-6.txt > tmp_tree-annotation_2.txt")
system(str_c("sed -e 's/ /_/g' tmp_tree-annotation_2.txt > ./",outfolder,"Phylogenetic_tree/tree-annotation_2.txt"))
system("rm tmp*")

# Extract all phyla to plot
labels <- filter(tidy_classified_reads_april_absolute, TaxRank == "P") %>%
  select(Name) %>%
  unique() 
labels$ring_hight <- "ring_height"
```


```{bash eval=FALSE}
# can take a while (>20 min)

DATE=`date +%Y-%m-%d`
outfolder="${DATE}_PuntSeq_R-analysis_output/"
sub_folder="${outfolder}Phylogenetic_tree/"

mkdir ${sub_folder}

tree="tax_slv_ssu_132_annotated"

# download tree of life from github
wget -nc https://raw.githubusercontent.com/d-j-k/puntseq/master/${tree}.tre -O ${sub_folder}${tree}.tre --no-check-certificate

## Visualise using the graphlan package

# Activate conda environment 
source ~/anaconda3/etc/profile.d/conda.sh
conda activate PuntSeq-analysis-env

#Installation of graphlan tool
#conda install -c bioconda graphlan

# Print version information
graphlan.py -v

# Add annotation to the tree and overlay with Cam seq data
graphlan_annotate.py ${sub_folder}${tree}.tre ${sub_folder}${tree}.annot1.txt --annot ${sub_folder}tree-annotation_1.txt

#graphlan_annotate.py ${sub_folder}${tree}.annot1.txt ${sub_folder}${tree}.annot2.txt --annot ${sub_folder}tree-annotation_2.txt

# Plot tree and save as .png file
#graphlan.py ${sub_folder}${tree}.tre ${sub_folder}${tree}.plot0.png --format png --dpi 300 --size 15 --pad 0.6

graphlan.py ${sub_folder}${tree}.annot1.txt ${sub_folder}${tree}.plot1.png --format png --dpi 300 --size 15 --pad 0.6

#graphlan.py ${sub_folder}${tree}.annot2.txt ${sub_folder}${tree}.plot2.png --format png --dpi 300 --size 15 --pad 0.6 

# Deactivate conda environment
conda deactivate
```
